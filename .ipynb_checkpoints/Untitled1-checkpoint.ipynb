{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ff8b8ac-dabb-4994-878e-b361c3c14246",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-0.3.11-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-community\n",
      "  Using cached langchain_community-0.3.11-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain-core\n",
      "  Using cached langchain_core-0.3.24-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-openai\n",
      "  Using cached langchain_openai-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.9.0.post1-cp311-cp311-win_amd64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\helin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.36-cp311-cp311-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.11.10-cp311-cp311-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.3,>=0.1.17 (from langchain)\n",
      "  Using cached langsmith-0.2.3-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy<2,>=1.22.4 (from langchain)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/61.0 kB ? eta -:--:--\n",
      "     -------------------------------------- 61.0/61.0 kB 651.3 kB/s eta 0:00:00\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.10.3-py3-none-any.whl.metadata (172 kB)\n",
      "     ---------------------------------------- 0.0/172.0 kB ? eta -:--:--\n",
      "     ---------------- ---------------------- 71.7/172.0 kB 2.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- 172.0/172.0 kB 2.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\helin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Using cached pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\helin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\helin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core) (4.12.2)\n",
      "Collecting openai<2.0.0,>=1.55.3 (from langchain-openai)\n",
      "  Downloading openai-1.57.3-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.8.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\helin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading propcache-0.2.1-cp311-cp311-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.18.3-cp311-cp311-win_amd64.whl.metadata (71 kB)\n",
      "     ---------------------------------------- 0.0/71.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 71.4/71.4 kB ? eta 0:00:00\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\helin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\helin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.3,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.12-cp311-none-win_amd64.whl.metadata (42 kB)\n",
      "     ---------------------------------------- 0.0/42.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.9/42.9 kB ? eta 0:00:00\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.3,>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\helin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.55.3->langchain-openai) (4.7.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.55.3->langchain-openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.55.3->langchain-openai)\n",
      "  Downloading jiter-0.8.2-cp311-cp311-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\helin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.55.3->langchain-openai) (1.3.1)\n",
      "Collecting tqdm>4 (from openai<2.0.0,>=1.55.3->langchain-openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.1 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.27.1-cp311-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\helin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\helin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\helin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\helin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 41.5/41.5 kB ? eta 0:00:00\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\helin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\helin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\helin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.55.3->langchain-openai) (0.4.6)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Using cached langchain-0.3.11-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_community-0.3.11-py3-none-any.whl (2.5 MB)\n",
      "Using cached langchain_core-0.3.24-py3-none-any.whl (410 kB)\n",
      "Using cached langchain_openai-0.2.12-py3-none-any.whl (50 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading faiss_cpu-1.9.0.post1-cp311-cp311-win_amd64.whl (13.8 MB)\n",
      "   ---------------------------------------- 0.0/13.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/13.8 MB 5.2 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.8/13.8 MB 8.1 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.3/13.8 MB 9.2 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.9/13.8 MB 10.3 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.5/13.8 MB 10.8 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.1/13.8 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 3.7/13.8 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 4.3/13.8 MB 12.0 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.9/13.8 MB 11.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 5.5/13.8 MB 11.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 6.0/13.8 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 6.7/13.8 MB 12.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 7.3/13.8 MB 12.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 7.9/13.8 MB 12.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 8.6/13.8 MB 12.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 9.1/13.8 MB 12.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.8/13.8 MB 12.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 10.2/13.8 MB 12.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.7/13.8 MB 12.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 11.3/13.8 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.8/13.8 MB 12.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 12.4/13.8 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.0/13.8 MB 12.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.5/13.8 MB 12.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.8/13.8 MB 12.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.8/13.8 MB 11.9 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.11.10-cp311-cp311-win_amd64.whl (442 kB)\n",
      "   ---------------------------------------- 0.0/442.3 kB ? eta -:--:--\n",
      "   --------------------------------------  440.3/442.3 kB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 442.3/442.3 kB 9.2 MB/s eta 0:00:00\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\n",
      "Using cached langsmith-0.2.3-py3-none-any.whl (320 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.6/15.8 MB 12.9 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 1.2/15.8 MB 12.4 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.7/15.8 MB 12.1 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 2.3/15.8 MB 12.1 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.8/15.8 MB 12.8 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 3.4/15.8 MB 12.6 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 3.9/15.8 MB 11.9 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 4.5/15.8 MB 12.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 5.0/15.8 MB 11.9 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 5.6/15.8 MB 12.3 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 6.1/15.8 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 6.7/15.8 MB 12.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 7.3/15.8 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 7.9/15.8 MB 12.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 8.4/15.8 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 9.0/15.8 MB 12.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 9.6/15.8 MB 12.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 10.1/15.8 MB 12.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 10.7/15.8 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 11.2/15.8 MB 12.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.8/15.8 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.4/15.8 MB 12.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.9/15.8 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.5/15.8 MB 12.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 14.1/15.8 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.7/15.8 MB 12.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.2/15.8 MB 12.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 12.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 11.7 MB/s eta 0:00:00\n",
      "Downloading openai-1.57.3-py3-none-any.whl (390 kB)\n",
      "   ---------------------------------------- 0.0/390.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 390.2/390.2 kB 12.3 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.10.3-py3-none-any.whl (456 kB)\n",
      "   ---------------------------------------- 0.0/457.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 457.0/457.0 kB 14.0 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.27.1-cp311-none-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.6/2.0 MB 13.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.2/2.0 MB 12.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 12.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 12.6 MB/s eta 0:00:00\n",
      "Using cached pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
      "Downloading SQLAlchemy-2.0.36-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.1 MB 15.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.1/2.1 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.7/2.1 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 12.1 MB/s eta 0:00:00\n",
      "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading tiktoken-0.8.0-cp311-cp311-win_amd64.whl (884 kB)\n",
      "   ---------------------------------------- 0.0/884.5 kB ? eta -:--:--\n",
      "   ---------------------- ---------------- 501.8/884.5 kB 10.5 MB/s eta 0:00:01\n",
      "   --------------------------------------- 884.5/884.5 kB 11.2 MB/s eta 0:00:00\n",
      "Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl (51 kB)\n",
      "   ---------------------------------------- 0.0/51.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 51.6/51.6 kB ? eta 0:00:00\n",
      "Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl (298 kB)\n",
      "   ---------------------------------------- 0.0/298.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 298.9/298.9 kB 9.3 MB/s eta 0:00:00\n",
      "Downloading jiter-0.8.2-cp311-cp311-win_amd64.whl (206 kB)\n",
      "   ---------------------------------------- 0.0/206.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 206.7/206.7 kB 13.1 MB/s eta 0:00:00\n",
      "Using cached marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
      "Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Downloading orjson-3.10.12-cp311-none-win_amd64.whl (135 kB)\n",
      "   ---------------------------------------- 0.0/135.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 135.1/135.1 kB ? eta 0:00:00\n",
      "Downloading propcache-0.2.1-cp311-cp311-win_amd64.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.4/44.4 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading regex-2024.11.6-cp311-cp311-win_amd64.whl (274 kB)\n",
      "   ---------------------------------------- 0.0/274.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 274.1/274.1 kB 8.5 MB/s eta 0:00:00\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.18.3-cp311-cp311-win_amd64.whl (91 kB)\n",
      "   ---------------------------------------- 0.0/91.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 91.0/91.0 kB 5.4 MB/s eta 0:00:00\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: tqdm, tenacity, regex, python-dotenv, pydantic-core, propcache, orjson, numpy, mypy-extensions, multidict, marshmallow, jsonpatch, jiter, httpx-sse, greenlet, frozenlist, distro, annotated-types, aiohappyeyeballs, yarl, typing-inspect, tiktoken, SQLAlchemy, requests-toolbelt, pydantic, faiss-cpu, aiosignal, pydantic-settings, openai, langsmith, dataclasses-json, aiohttp, langchain-core, langchain-text-splitters, langchain-openai, langchain, langchain-community\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.0\n",
      "    Uninstalling numpy-2.2.0:\n",
      "      Successfully uninstalled numpy-2.2.0\n",
      "Successfully installed SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.4 aiohttp-3.11.10 aiosignal-1.3.1 annotated-types-0.7.0 dataclasses-json-0.6.7 distro-1.9.0 faiss-cpu-1.9.0.post1 frozenlist-1.5.0 greenlet-3.1.1 httpx-sse-0.4.0 jiter-0.8.2 jsonpatch-1.33 langchain-0.3.11 langchain-community-0.3.11 langchain-core-0.3.24 langchain-openai-0.2.12 langchain-text-splitters-0.3.2 langsmith-0.2.3 marshmallow-3.23.1 multidict-6.1.0 mypy-extensions-1.0.0 numpy-1.26.4 openai-1.57.3 orjson-3.10.12 propcache-0.2.1 pydantic-2.10.3 pydantic-core-2.27.1 pydantic-settings-2.6.1 python-dotenv-1.0.1 regex-2024.11.6 requests-toolbelt-1.0.0 tenacity-9.0.0 tiktoken-0.8.0 tqdm-4.67.1 typing-inspect-0.9.0 yarl-1.18.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install langchain langchain-community langchain-core langchain-openai python-dotenv faiss-cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d3364bb-ef14-4fe8-812c-8c180a5e98a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\helin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\helin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\helin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\helin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\helin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\helin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9110113-9156-46ff-a35a-399f8dc47503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from pathlib import Path\n",
    "from langchain_openai import ChatOpenAI,OpenAIEmbeddings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.agents import Tool, AgentExecutor, ConversationalAgent\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain import OpenAI, LLMChain\n",
    "from langchain.chains import RetrievalQA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccbff2b0-adeb-4cd6-9736-ee12da349139",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "485b6e6b-e9cc-43a3-8e66-4cf81204d724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dba04e2-a5bd-411f-bd31-225d6fdc6d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c159527-38de-49cf-8253-a3c55d568657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kategori</th>\n",
       "      <th>urun</th>\n",
       "      <th>icindekiler</th>\n",
       "      <th>Fiyat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baslangiclar</td>\n",
       "      <td>Nachos</td>\n",
       "      <td>El yapimi tortilla cips, cheddar, yesil sogan,...</td>\n",
       "      <td>120 TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baslangiclar</td>\n",
       "      <td>Mozzarella cubuklari</td>\n",
       "      <td>Pane mozzarella cubuklari, pesto sos</td>\n",
       "      <td>115 TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baslangiclar</td>\n",
       "      <td>Tavuk Kanatlari</td>\n",
       "      <td>Pane tavuk kanatlari; sos secenekleri: BBQ, ha...</td>\n",
       "      <td>125 TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baslangiclar</td>\n",
       "      <td>Karides Tava</td>\n",
       "      <td>Jumbo karides, sarimsak, tereyagi, limon suyu,...</td>\n",
       "      <td>150 TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baslangiclar</td>\n",
       "      <td>Falafel Tabagi</td>\n",
       "      <td>Falafel koftesi, humus, tahin sos, salata</td>\n",
       "      <td>75 TL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Kategori                  urun  \\\n",
       "0  Baslangiclar                Nachos   \n",
       "1  Baslangiclar  Mozzarella cubuklari   \n",
       "2  Baslangiclar       Tavuk Kanatlari   \n",
       "3  Baslangiclar          Karides Tava   \n",
       "4  Baslangiclar        Falafel Tabagi   \n",
       "\n",
       "                                         icindekiler   Fiyat  \n",
       "0  El yapimi tortilla cips, cheddar, yesil sogan,...  120 TL  \n",
       "1               Pane mozzarella cubuklari, pesto sos  115 TL  \n",
       "2  Pane tavuk kanatlari; sos secenekleri: BBQ, ha...  125 TL  \n",
       "3  Jumbo karides, sarimsak, tereyagi, limon suyu,...  150 TL  \n",
       "4          Falafel koftesi, humus, tahin sos, salata   75 TL  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = ('menu1.csv') # insert the path of the csv file\n",
    "data = pd.read_csv(file_path,sep=';')\n",
    "\n",
    "#preview the csv file\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59bf77ff-c745-4733-8055-cd52b47ef066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mozzarella cubuklari'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.urun[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b93ebfa1-5124-4f32-8517-3679e70b6f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Nachos', 'Mozzarella cubuklari', 'Tavuk Kanatlari',\n",
       "       'Karides Tava', 'Falafel Tabagi', 'Sebzeli Spring Roll',\n",
       "       'Mercimek corbasi', 'Kremali Mantar corbasi', 'Domates corbasi',\n",
       "       'Tavuk Suyu corbasi', 'Balkabagi corbasi', 'Peynirli Tavuk Pizza',\n",
       "       'Etli Pizza', 'Vegan Pizza', 'Acili Deniz Pizza',\n",
       "       'Margarita Pizza', 'Klasik Burger', 'Cheeseburger', 'Siyah Burger',\n",
       "       'Tavuk Burger', 'Acili Burger', 'izgara Tavuk', 'Antrikot',\n",
       "       'Somon izgara', 'Sebzeli Guvec', 'Sufle', 'Tiramisu', 'Cheesecake',\n",
       "       'Firin Sutlac', nan], dtype=object)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.urun.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "62a3ff50-324a-4d2b-8f97-af49f8ef14c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader(file_path=file_path)\n",
    "docs = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "abd7989b-7e92-4265-8222-a1add9c0cb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "index = faiss.IndexFlatL2(len(OpenAIEmbeddings().embed_query(\" \")))\n",
    "vector_store = FAISS(\n",
    "    embedding_function=OpenAIEmbeddings(),\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9f6e330f-6c69-4f12-a4e2-493c223dcdfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a29d5b87-1650-4e63-9fcc-e3de1722c566',\n",
       " '9ad068a2-cd32-4aea-ab95-2527a1377dd9',\n",
       " 'b4b5a143-6825-412f-8810-537d809efb5b',\n",
       " 'a8108711-5929-440f-9458-540d310ae065',\n",
       " '95276f8b-d886-4f44-a813-d38304b80663',\n",
       " '08a4ad96-997c-4e36-a03c-3a769c9465b4',\n",
       " 'f5c78c76-eddf-49ea-9124-1f3b62257232',\n",
       " 'b68ec6f3-634f-4666-a87a-e7af56c6abc3',\n",
       " '22b09f43-5d2d-472e-bb67-1f6bf05f0ca1',\n",
       " 'c245c2d4-2c45-45a2-a7af-f4a0ce6931be',\n",
       " 'd04add0d-7b3a-49da-ab39-53352381e98b',\n",
       " '23af278a-9759-4834-8860-112799a8d517',\n",
       " '568f76c4-7c0c-452a-a5d9-9b376eeb7316',\n",
       " '5ae63dc3-9c3c-41cf-93dc-3fe206b0a586',\n",
       " 'cbd2f7cd-f1be-4883-b468-db38d1348a06',\n",
       " 'e03bbbcb-5eb4-493d-a73f-0f46404ccb42',\n",
       " '26299e47-c691-4318-b23e-190e9da6e79f',\n",
       " 'fb422399-4ee2-4b7e-a296-4cf6f3eac9db',\n",
       " 'e231b500-dc4e-4661-9167-f19a249c5d2f',\n",
       " 'f990ffe9-6591-4b58-a317-5095b900cf0d',\n",
       " '71a8be1f-9749-441d-9ac6-c8afc62964b6',\n",
       " '22e11dd6-aa2d-42d5-a6fe-cab11764a552',\n",
       " 'fdb52865-78ed-45e8-9597-5cc422ed79d5',\n",
       " '4c33ad3e-8927-4959-a4d7-5db95a01b03f',\n",
       " '88df3771-684a-41b9-bc14-e909f77adaf8',\n",
       " 'a110414a-675e-4b88-a1c6-276444f0a4ba',\n",
       " 'f4984367-ce8e-4d32-b2ad-6961dfd250cb',\n",
       " 'f4236b31-b7d4-40d2-85d1-b1b5a7152cfd',\n",
       " '1a1cb3dc-3063-428a-b10b-d7383a84097b',\n",
       " 'c8bf2e1a-f75d-49f2-a72c-d5eee8223ab5']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(documents=docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa11a26b-2271-48cb-848a-81f9d06882e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c734f939-cb78-4a99-b1d9-5afe28d7c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationStringBufferMemory\n",
    "from langchain.chains import RetrievalQA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9aad3b3-f7bb-4e34-b0a4-9d244af0d39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9bd904ed-c5cf-4330-b7bf-fc34295b0ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Prompt\n",
    "system_prompt = (\n",
    "    \"You are a professional waiter at a high-quality restaurant. \"\n",
    "    \"Your job is to politely and concisely answer questions about the menu. \"\n",
    "    \"Always start your response with a warm greeting, such as 'Welcome!' or 'Hello, how can I assist you today?'. \"\n",
    "    \"Use the provided menu context to answer all questions. \"\n",
    "    \"If the item is not available, respond with: 'I’m sorry, that item is not on the menu.' \"\n",
    "    \"If you don't know the answer, say: 'I’m sorry, I’m not sure about that.' \"\n",
    "    \"When confirming an order, repeat it politely and thank the guest. \"\n",
    "    \"Do not recommend items outside the provided menu. \"\n",
    "    \"Structure your responses as follows: \"\n",
    "    \"1. Start with a warm greeting. \"\n",
    "    \"2. Provide a clear and concise answer to the question. \"\n",
    "    \"3. Close with a polite and professional offer to assist further. \"\n",
    "    \"Only response the main question. Don't say anything except the question's response. \"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "# ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Create the question-answer chain\n",
    "#question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9df0ce36-f0f7-4004-97f0-101840f0c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List ,Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "class sip(TypedDict):\n",
    "    \"\"\"Represents a sentence describing an ordered item.\"\"\"\n",
    "\n",
    "    sip_name: Annotated[str, ..., \"Name of the ordered item, such as a menu item.\"]\n",
    "    sip_count: Annotated[int, ..., \"Quantity of the ordered item.\"]\n",
    "    sip_mod: Annotated[str, ..., \"changed ingredient for item.\"]\n",
    "\n",
    "class non_sip(TypedDict):\n",
    "    \"\"\"Represents a sentence describing a non-ordered item.\"\"\"\n",
    "\n",
    "    non_sip_name: Annotated[str, ..., \"Name of the item, without an order (e.g., general reference to a thing or asking questions about it).\"]\n",
    "    non_sip_count: Annotated[int, ..., \"Count of the item, if mentioned, but not part of an order.\"]\n",
    "\n",
    "class del_item(TypedDict):\n",
    "    \"\"\"Represents a sentence describing an item to be deleted from the order.\"\"\"\n",
    "    \n",
    "    del_name: Annotated[str, ..., \"Name of the ordered item that is being canceled or removed.\"]\n",
    "    del_count: Annotated[int, ..., \"Quantity of the item that is being canceled or removed. This value can be positive or indicate the total amount to be canceled.\"]\n",
    "    is_all: Annotated[Optional[bool], \"Indicates if the entire item category (e.g., all 'hamburgers') is being canceled. 'True' means all instances of that item will be canceled, 'False' means just a specific quantity or instance.\"]\n",
    "    description: Annotated[Optional[str], \"Describes the user's intent to cancel all instances of a specific item category, like 'hamburgers', without providing a specific count. This could include phrases like 'I want to cancel all hamburgers'.\"]\n",
    "\n",
    "class FinalResponse(BaseModel):\n",
    "    final_output: List[Union[sip, non_sip, del_item]]\n",
    "\n",
    "# Example of structured output model usage\n",
    "structured_llm = llm.with_structured_output(FinalResponse)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f5fc58-698f-4d86-b3ec-bd2684701950",
   "metadata": {},
   "source": [
    "# MODELİN ERİLEN CEVAPLARI AYIKLAMASI YERİNE İNPUTU DİCT HALİNE DÖNÜŞTÜRMESİNİ SAĞLIYORUZ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbc1a262-eca2-4fbb-ab1c-7df50dd83cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "system1 = \"\"\"You are an expert at converting user questions into database queries. \\\n",
    "customers will talk you about the menu and you will tke the order or answer their questions \\\n",
    "you have to understand the input for deciding to take an order or answer the question \\\n",
    "if you dont understand the meaning of a sentence or the intent tell it \"\"\"\n",
    "\n",
    "prompt1 = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system1),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a2f9322-0479-4285-a1ba-4883a8049360",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm1 = llm.with_structured_output(FinalResponse)\n",
    "query_analyzer = prompt1 | structured_llm1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef44c6a-637c-4369-bfab-252daccc7a81",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## query analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b314895d-f258-40f6-bd4b-3ceb7a4d1ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalResponse(final_output=[{'sip_name': 'çay', 'sip_count': 2, 'sip_mod': ''}])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyzer.invoke(\"bana iki çay yolla \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97873046-d88d-44a2-90b8-5d2c1f5b117d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalResponse(final_output=[{'sip_name': 'latte', 'sip_count': 2}])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyzer.invoke(\"2 latte alabilir miyim \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "439416cc-2244-4157-832f-2ba6890ca9d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalResponse(final_output=[{'non_sip_name': 'Menüdeki içecekler', 'non_sip_count': 1}, {'non_sip_name': 'Menüdeki yiyecekler', 'non_sip_count': 1}])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyzer.invoke(\"menüde neler var\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "09b5d772-ae77-4b17-93c6-51d6d7cab391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-13 16:48:33,945 - httpx - INFO\n",
      "Msg: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FinalResponse(final_output=[{'sip_name': 'latte', 'sip_count': 2}])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyzer.invoke(\"2 latte alabilir miyim \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bfca282-88ee-44f5-85e7-25f7bd41464a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalResponse(final_output=[{'non_sip_name': 'makarna tarifi', 'non_sip_count': 1}])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyzer.invoke(\"makarnayı nasıl yapıyosunuz \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa5a22e9-a17b-4f40-9d22-1ad637dff215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalResponse(final_output=[{'non_sip_name': 'acılı biftek', 'non_sip_count': 1}])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyzer.invoke(\"acılı biftek ne kadar acı\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d94fafa-195f-41bd-a24d-f87fa5c75ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalResponse(final_output=[{'sip_name': 'pizza', 'sip_count': 1, 'sip_mod': 'acı biberli, kasarsız'}])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyzer.invoke(\"acı biberli ve kasarsız pizza almak istiyorum \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38fbc434-41c2-47d2-b4ad-72325561d3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalResponse(final_output=[{'non_sip_name': 'latte', 'non_sip_count': 1}])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyzer.invoke(\"latteyi laktozsuz süt ile mi yapıyorsunuz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "908b73c7-5a75-474b-ae8e-3b1ca68f0fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalResponse(final_output=[{'sip_name': 'keikli', 'sip_count': 2, 'sip_mod': ''}, {'sip_name': 'kremalı makarna', 'sip_count': 1, 'sip_mod': ''}])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyzer.invoke(\"2 keikli 1 de kremalı makarna istiyorum \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ed362e6a-b615-4c9a-a843-7e885e92d58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-13 16:49:10,191 - httpx - INFO\n",
      "Msg: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FinalResponse(final_output=[{'sip_name': 'hamburger', 'sip_count': 2}, {'sip_name': 'kola', 'sip_count': 1}])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyzer.invoke(\"2 hamburger istiyorum yanına 1 kola \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bca68cbb-da4a-4da5-899a-52608a97668f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-13 16:49:11,695 - httpx - INFO\n",
      "Msg: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FinalResponse(final_output=[{'del_name': 'pizza', 'del_count': 1, 'is_all': None, 'description': None}])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyzer.invoke(\"1 pizzayı silelim \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad95c649-29ca-41cc-a36e-a6bcfb94f954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalResponse(final_output=[{'del_name': 'hamburger', 'del_count': 1, 'is_all': None, 'description': 'Hamburgerlerden vazgeçtim'}])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyzer.invoke(\"hamburgerlerden vazgeçtim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f12634-da15-4cc5-a70c-8b69b6becb10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15c2c43-259b-40fb-a754-cc6622917c95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107622db-c144-47e8-bc79-770a44ae81f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97d10d87-578f-47a0-9b4f-1828fd35440a",
   "metadata": {},
   "source": [
    "# ayıklanmış itemlere menü kontrolü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b9f1390-f60d-412f-a54a-ea4f7f122b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sip_in_menu(final_response: FinalResponse, data: pd.DataFrame) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Checks if `sip` items in the FinalResponse exist in the `urun` column of the menu DataFrame.\n",
    "\n",
    "    :param final_response: FinalResponse object containing the structured output.\n",
    "    :param menu_data: pandas DataFrame containing the menu with a `urun` column.\n",
    "    :return: List of results with each `sip` item and its existence status.\n",
    "    \"\"\"\n",
    "    # 'urun' sütunundaki benzersiz ürünleri al\n",
    "    menu_items = set(data['urun'].str.lower().unique())\n",
    "    \n",
    "    # Sonuçları tutmak için liste\n",
    "    results = []\n",
    "\n",
    "    # FinalResponse içindeki `sip` nesnelerini kontrol et\n",
    "    for item in final_response.final_output:\n",
    "        if isinstance(item, dict) and \"sip_name\" in item:\n",
    "            sip_name_lower = item[\"sip_name\"].lower()\n",
    "            exists = sip_name_lower in menu_items\n",
    "            results.append({\n",
    "                \"sip_name\": item[\"sip_name\"],\n",
    "                \"sip_count\": item[\"sip_count\"],\n",
    "                \"sip_mod\":item[\"sip_mod\"],\n",
    "                \"exists_in_menu\": exists\n",
    "            })\n",
    "        else:\n",
    "             results.append({\n",
    "                \"non_sip_name\": item[\"non_sip_name\"],\n",
    "                \"non_sip_count\": item[\"non_sip_count\"]})\n",
    "             \n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39ca8fac-3cf2-4bf6-b581-2bc01c415f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sip_name': 'Karides tava', 'sip_count': 2, 'exists_in_menu': True}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_sip_in_menu(final_response=FinalResponse(final_output=[{'sip_name': 'Karides tava', 'sip_count': 2}]),data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7f074b2e-6efe-494c-ae20-c50817643422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sip_name': 'klasik burger',\n",
       "  'sip_count': 2,\n",
       "  'sip_mod': '',\n",
       "  'exists_in_menu': True},\n",
       " {'sip_name': 'kola', 'sip_count': 1, 'sip_mod': '', 'exists_in_menu': False}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_sip_in_menu(final_response=query_analyzer.invoke(\"2 klasik burger istiyorum yanına 1 kola \"),data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6358d5ec-e118-40e8-999d-2578a2478755",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m quest\u001b[38;5;241m=\u001b[39mquery_analyzer\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2 NACHOS istemiyorum\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mcheck_sip_in_menu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_response\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquest\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[38], line 16\u001b[0m, in \u001b[0;36mcheck_sip_in_menu\u001b[1;34m(final_response, data)\u001b[0m\n\u001b[0;32m     13\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# FinalResponse içindeki `sip` nesnelerini kontrol et\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfinal_response\u001b[49m\u001b[38;5;241m.\u001b[39mfinal_output:\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msip_name\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m item:\n\u001b[0;32m     18\u001b[0m         sip_name_lower \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msip_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mlower()\n",
      "Cell \u001b[1;32mIn[38], line 16\u001b[0m, in \u001b[0;36mcheck_sip_in_menu\u001b[1;34m(final_response, data)\u001b[0m\n\u001b[0;32m     13\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# FinalResponse içindeki `sip` nesnelerini kontrol et\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfinal_response\u001b[49m\u001b[38;5;241m.\u001b[39mfinal_output:\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msip_name\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m item:\n\u001b[0;32m     18\u001b[0m         sip_name_lower \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msip_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mlower()\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:1697\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:634\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:1368\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:1311\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:494\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2185\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2182\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2184\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2185\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2187\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2190\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2254\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2251\u001b[0m                 queue\u001b[38;5;241m.\u001b[39mput(internal_cmd)\n\u001b[0;32m   2252\u001b[0m                 wait_timeout \u001b[38;5;241m=\u001b[39m TIMEOUT_FAST\n\u001b[1;32m-> 2254\u001b[0m         \u001b[43mnotify_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2255\u001b[0m         notify_event\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m   2257\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    627\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:331\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 331\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    333\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "quest=query_analyzer.invoke(\"2 NACHOS istemiyorum\")\n",
    "check_sip_in_menu(final_response=quest,data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "46296d91-ec6a-4a73-98dd-9d4dc2b727d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_history=[]\n",
    "quest=query_analyzer.invoke(\"2 izgara tavuk istiyorum\")\n",
    "deneme=check_sip_in_menu(final_response=quest,data=data)\n",
    "for result in deneme:\n",
    "            if result.get(\"exists_in_menu\", True):\n",
    "                order_history.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "49abaab2-2e36-4fc1-8270-197ed0c763b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sip_name': 'izgara tavuk',\n",
       " 'sip_count': 2,\n",
       " 'sip_mod': '',\n",
       " 'exists_in_menu': True}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_history[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1391986d-be5a-4646-a463-6a1df233a811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'non_sip_name': 'Mozzarella Pizza İçindekiler', 'non_sip_count': 1}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quest=query_analyzer.invoke(\"mozarella pizzanın içinde ne var \")\n",
    "check_sip_in_menu(final_response=quest,data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cb0d0197-3464-4eb6-98d8-149472fe67ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\helin\\AppData\\Local\\Temp\\ipykernel_21956\\3353824168.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e978700a-b33f-4343-99ad-baadddd8b34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    input_key=\"query\",\n",
    "    return_source_documents=False,\n",
    "    memory=memory  # Hafızayı buraya ekliyoruz\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c6464b-303a-4852-9fee-b021a07e8d86",
   "metadata": {},
   "source": [
    "# iki zinciri birlikte çağırma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2f0a3efe-1d2c-48aa-ad75-bf9c117cceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_conversation(query: str):\n",
    "    # RAG zincirinden yanıt alıyoruz\n",
    "    rag_output = rag_chain.invoke({\"query\": query})\n",
    "\n",
    "    quest=query_analyzer.invoke({\"query\": query})\n",
    "\n",
    "\n",
    "    # check_sip_in_menu fonksiyonunu çalıştırıyoruz\n",
    "    sip_check_result = check_sip_in_menu(quest, data)\n",
    "\n",
    "    # Hem RAG çıktısını hem de sip kontrolünü döndürüyoruz\n",
    "    return {\n",
    "        \"rag_response\": rag_output,\n",
    "        \"sip_check_result\": sip_check_result\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a16535eb-56fa-4a9f-92d2-286e31b2ab65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'sütlaç olsun iki tane ama icinde tarcin olmasın ',\n",
       " 'chat_history': [HumanMessage(content='tüm menüyü ver', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Menü:\\n\\n1. Ana Yemekler\\n   - Izgara Tavuk: Izgara tavuk göğsü, sebze garnitürü, sarımsaklı patates püresi - Fiyat: 130 TL\\n   - Sebzeli Güveç: Fırınlanmış taze sebzeler, domates sos - Fiyat: 85 TL\\n\\n2. Hamburgerler\\n   - Tavuk Burger: Çıtır tavuk, cheddar, domates, tatlı soğan, sarımsak sos - Fiyat: 100 TL\\n\\n3. Başlangıçlar\\n   - Tavuk Kanatları: Pane tavuk kanatları, sos seçenekleri: BBQ, hardal, ketçap, mayonez - Fiyat: 125 TL', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='tavuk burger ver', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Tavuk Burger'in içindekileri ve fiyatı şu şekildedir:\\n\\n- İçindekiler: Çıtır tavuk, cheddar, domates, tatlı soğan, sarımsak sos\\n- Fiyat: 100 TL\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='sütlaç olsun iki tane ama icinde tarcin olmasın ', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Üzgünüm, fakat mevcut seçeneklerde tarçın içermeyen bir sütlaç bulunmamaktadır.', additional_kwargs={}, response_metadata={})],\n",
       " 'result': 'Üzgünüm, fakat mevcut seçeneklerde tarçın içermeyen bir sütlaç bulunmamaktadır.'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['rag_response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7fb87b63-a548-4a04-836e-bb2cb1db53d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Response: Üzgünüm, fakat mevcut seçeneklerde tarçın içermeyen bir sütlaç bulunmamaktadır.\n",
      "Sip Check Result: [{'sip_name': 'sütlaç', 'sip_count': 2, 'sip_mod': 'tarçınsız', 'exists_in_menu': False}]\n"
     ]
    }
   ],
   "source": [
    "query = \"sütlaç olsun iki tane ama icinde tarcin olmasın \"\n",
    "output = run_conversation(query)\n",
    "\n",
    "# Sonuçları yazdırıyoruz\n",
    "dic=output['rag_response']\n",
    "\n",
    "print(\"RAG Response:\", dic['result'])\n",
    "print(\"Sip Check Result:\", output['sip_check_result'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a3044ce4-00da-40ef-b107-14bec7132644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_spelling_with_gpt(text: str) -> str:\n",
    "    prompt = f\"Yazım hatalarını düzelt: '{text}'\"\n",
    "    response = llm(prompt)  # Model cevabını alıyoruz\n",
    "\n",
    "    # Yanıtın türünü kontrol ediyoruz\n",
    "    print(type(response))  # Yanıtın türünü öğrenin\n",
    "    print(response)        # Yanıtı yazdırarak yapısını görün\n",
    "\n",
    "    # AIMessage objesinin doğru özelliğine erişim (Örneğin, 'content' olabilir)\n",
    "    if hasattr(response, 'text'):  # Eğer 'text' özelliği varsa\n",
    "        corrected_text = response.text.strip()\n",
    "    elif hasattr(response, 'content'):  # 'content' özelliği varsa\n",
    "        corrected_text = response.content.strip()\n",
    "    else:\n",
    "        corrected_text = str(response).strip()  # Eğer başka bir formatta ise, string olarak al\n",
    "\n",
    "    return corrected_text\n",
    "    # bu fonksiyon düzenlenip, kelimeleri menudeki var olan urunlere bağlayabilmeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f5851c40-3db2-45c4-a3eb-9f241060df13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='Doğru yazımı: \"deneme\" şeklindedir.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 20, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'stop', 'logprobs': None} id='run-e50e1edb-9e44-47d3-ab22-73598043f628-0' usage_metadata={'input_tokens': 20, 'output_tokens': 14, 'total_tokens': 34, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Doğru yazımı: \"deneme\" şeklindedir.'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_spelling_with_gpt(\"denemeeee\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c428ce-aade-4653-b5f0-442918085b3d",
   "metadata": {},
   "source": [
    "# sonsuz döngü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c06be07-e68d-4280-b910-ceb0b0842381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Soru (exit yazarsanız çıkılır):  merhaba\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Yanıtı: Merhaba! Size nasıl yardımcı olabilirim?\n",
      "Sipariş Durumu: [{'non_sip_name': 'Merhaba', 'non_sip_count': 1}]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Soru (exit yazarsanız çıkılır):  başlangıç olarak neler yiyebilirim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Yanıtı: Başlangıç olarak aşağıdaki seçenekleri yiyebilirsiniz:\n",
      "\n",
      "1. Tavuk Kanatları - Fiyat: 125 TL (Pane tavuk kanatları; sos seçenekleri: BBQ, hardal, ketçap, mayonez)\n",
      "2. Nachos - Fiyat: 120 TL (El yapımı tortilla cips; cheddar, yeşil soğan, jalapenos, siyah zeytin)\n",
      "3. Sebzeli Spring Roll - Fiyat: 70 TL (Havuç, kabak, lahana, pirinç yufkası, tatlı ekşi sos)\n",
      "4. Karides Tava - Fiyat: 150 TL (Jumbo karides; sarımsak, tereyağı, limon suyu, baharatlar)\n",
      "Sipariş Durumu: [{'non_sip_name': 'Merhaba', 'non_sip_count': 1}, {'non_sip_name': 'meze', 'non_sip_count': 1}, {'non_sip_name': 'çorba', 'non_sip_count': 1}, {'non_sip_name': 'salata', 'non_sip_count': 1}]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Soru (exit yazarsanız çıkılır):  nachos alayım ben\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Yanıtı: Nachos siparişiniz alındı. Fiyatı 120 TL'dir. Başka bir şey ister misiniz?\n",
      "Sipariş Durumu: [{'non_sip_name': 'Merhaba', 'non_sip_count': 1}, {'non_sip_name': 'meze', 'non_sip_count': 1}, {'non_sip_name': 'çorba', 'non_sip_count': 1}, {'non_sip_name': 'salata', 'non_sip_count': 1}, {'sip_name': 'nachos', 'sip_count': 1, 'sip_mod': '', 'exists_in_menu': True}]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Soru (exit yazarsanız çıkılır):  ana yemek olarak ne yiyebilirim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Yanıtı: Ana yemek olarak aşağıdaki seçenekleri değerlendirebilirsiniz:\n",
      "\n",
      "1. Izgara Tavuk - Izgara tavuk göğsü, sebze garnitürü ve sarımsaklı patates püresi ile birlikte (Fiyat: 130 TL)\n",
      "2. Antrikot - Özel marine edilmiş antrikot, közlenmiş sebzeler ve patates püresi ile birlikte (Fiyat: 190 TL)\n",
      "3. Sebzeli Güveç - Fırınlanmış taze sebzeler ve domates sos ile birlikte (Fiyat: 85 TL)\n",
      "4. Somon Izgara - Taze limon soslu ızgara somon ve ızgara sebzeler ile birlikte (Fiyat: 180 TL)\n",
      "\n",
      "Bu seçeneklerden birini tercih edebilirsiniz.\n",
      "Sipariş Durumu: [{'non_sip_name': 'Merhaba', 'non_sip_count': 1}, {'non_sip_name': 'meze', 'non_sip_count': 1}, {'non_sip_name': 'çorba', 'non_sip_count': 1}, {'non_sip_name': 'salata', 'non_sip_count': 1}, {'sip_name': 'nachos', 'sip_count': 1, 'sip_mod': '', 'exists_in_menu': True}, {'non_sip_name': 'Ana Yemek Seçenekleri', 'non_sip_count': 1}]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Soru (exit yazarsanız çıkılır):  antrikot alayım bol soslu olsun\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Yanıtı: Antrikot menüsünde özel marine edilmiş antrikot bulunuyor. Ancak sos seçenekleri hakkında bilgi verilmemiş. Bol soslu olup olmadığını öğrenmek için restoran ile iletişime geçmenizi öneririm. 190 TL fiyatı var.\n",
      "Sipariş Durumu: [{'non_sip_name': 'Merhaba', 'non_sip_count': 1}, {'non_sip_name': 'meze', 'non_sip_count': 1}, {'non_sip_name': 'çorba', 'non_sip_count': 1}, {'non_sip_name': 'salata', 'non_sip_count': 1}, {'sip_name': 'nachos', 'sip_count': 1, 'sip_mod': '', 'exists_in_menu': True}, {'non_sip_name': 'Ana Yemek Seçenekleri', 'non_sip_count': 1}, {'sip_name': 'antrikot', 'sip_count': 1, 'sip_mod': 'bol soslu', 'exists_in_menu': True}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Sonsuz döngü\n",
    "def run_conversation():\n",
    "    order_history =[]\n",
    "\n",
    "    while True:\n",
    "        # Kullanıcıdan soru alıyoruz\n",
    "        query = input(\"Soru (exit yazarsanız çıkılır): \")\n",
    "\n",
    "        # 'exit' komutu ile çıkış\n",
    "        if query.lower() == \"exit\":\n",
    "            if order_history:\n",
    "                print(\"Siparişleriniz:\", order_history)\n",
    "                confirmation = input(\"Onaylıyor musunuz? (Evet/Hayır): \")\n",
    "                if confirmation.lower() == \"evet\":\n",
    "                    # Siparişleri bir .txt dosyasına kaydediyoruz\n",
    "                    with open(\"siparisler.txt\", \"w\") as f:\n",
    "                        for item in order_history:\n",
    "                            f.write(f\"{item['sip_name']} x {item['sip_count'] item[\"sip_mod\"]\"}\\n\")\n",
    "                    print(\"Siparişleriniz kaydedildi.\")\n",
    "                else:\n",
    "                    print(\"Siparişleriniz iptal edildi.\")\n",
    "            break  # Konuşmayı sonlandırıyoruz\n",
    "\n",
    "        #corrected_query = correct_spelling_with_gpt(query)\n",
    "        #print(f\"Düzeltilmiş Soru: {corrected_query}\")\n",
    "\n",
    "\n",
    "        # RAG zincirinden yanıt alıyoruz\n",
    "        rag_output = rag_chain.invoke({\"query\": query})\n",
    "        print(\"RAG Yanıtı:\", rag_output[\"result\"])\n",
    "\n",
    "        quest=query_analyzer.invoke({\"query\": query})\n",
    "\n",
    "        #silme isteği ise burda silmeliyiz order_history icinden\n",
    "        for item in quest.final_output:\n",
    "            if isinstance(item, dict) and \"del_name\" in item:\n",
    "                del_name_lower = item[\"del_name\"].lower()\n",
    "                #order_history dizisinden itemler gezilerek del_name ile aynı olanlar bulunup silinmeli sonra final outputtan deleteler kaldırılmalı.\n",
    "                for order in order_history:\n",
    "                    if order[\"sip_name\"]==del_name_lower:\n",
    "                       order[\"sip_count\"]= max((order[\"sip_count\"]-item[\"del_count\"]),0);\n",
    "                quest.final_output.remove(item)\n",
    "\n",
    "\n",
    "    # check_sip_in_menu fonksiyonunu çalıştırıyoruz\n",
    "        sip_check_result = check_sip_in_menu(quest, data)\n",
    "\n",
    "        # Siparişi hafızada tutuyoruz, eğer ürün menüde varsa\n",
    "        for result in sip_check_result:\n",
    "            if result.get(\"exists_in_menu\", True):\n",
    "                order_history.append(result)\n",
    "\n",
    "        # Kullanıcıya yanıt veriyoruz\n",
    "        \n",
    "        print(\"Sipariş Durumu:\", order_history)\n",
    "\n",
    "# Konuşma başlatma\n",
    "run_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1d4b545f-4d84-4360-bf7a-29cee73dd5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sip_name': 'izgara tavuk',\n",
       "  'sip_count': 2,\n",
       "  'sip_mod': '',\n",
       "  'exists_in_menu': True}]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a6e712e-ae42-4280-a15a-e531e93f3b63",
   "metadata": {},
   "source": [
    "# voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3e1ddb-3d58-46c8-a9e5-94f6bf4f6f31",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install gTTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cae6b1-ae5f-4f68-80a9-b6d423109b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install speechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4bf8f6-5b0b-44a2-ad95-a2c0ab0de427",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install PyAudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "571011dc-1f40-4138-8953-b231f1876b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mikrofon açık, konuşun...\n",
      "Dinleniyor...\n",
      "Duyulan: deneme dinleme konuş dinle beni Onur kork\n",
      "Ses dosyası kaydedildi: response_20241212203125.mp3\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import time\n",
    "from gtts import gTTS\n",
    "import os\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "\n",
    "def listen_from_microphone(duration=25):\n",
    "    recognizer = sr.Recognizer()\n",
    "\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Mikrofon açık, konuşun...\")\n",
    "\n",
    "        # Ortam gürültüsüne karşı ayar yap\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        start_time = time.time()\n",
    "\n",
    "        try:\n",
    "            print(\"Dinleniyor...\")\n",
    "            while True:\n",
    "                elapsed_time = time.time() - start_time\n",
    "                if elapsed_time > duration:  # Süreyi kontrol et\n",
    "                    print(f\"Zaman aşımı! {duration} saniye geçti.\")\n",
    "                    break\n",
    "\n",
    "                try:\n",
    "                    # Mikrofonu dinlemeye başla\n",
    "                    audio_data = recognizer.listen(source, timeout=10, phrase_time_limit=60)  # timeout: 10 saniye, phrase_time_limit: 60 saniye\n",
    "                    \n",
    "                    # Google'a gönderip metni al\n",
    "                    text = recognizer.recognize_google(audio_data, language=\"tr-TR\")\n",
    "                    print(f\"Duyulan: {text}\")\n",
    "                    return text  # Dinleme başarılı olursa metni döndür\n",
    "                except sr.UnknownValueError:\n",
    "                    print(\"Ses anlaşılamadı. Lütfen tekrar konuşun.\")\n",
    "                except sr.RequestError as e:\n",
    "                    print(f\"Google API'ye bağlanırken hata oluştu: {e}\")\n",
    "                except Exception as ex:\n",
    "                    print(f\"Bir hata oluştu: {ex}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Bir hata oluştu: {e}\")\n",
    "        return None\n",
    "\n",
    "def text_to_speech(text):\n",
    "    if text:\n",
    "        tts = gTTS(text=text, lang='tr')\n",
    "        \n",
    "        # Dosya adını benzersiz yapmak için tarih ve saat ekleyelim\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "        audio_filename = f\"response_{timestamp}.mp3\"\n",
    "        \n",
    "        try:\n",
    "            # Ses dosyasını kaydet\n",
    "            tts.save(audio_filename)\n",
    "            print(f\"Ses dosyası kaydedildi: {audio_filename}\")\n",
    "            \n",
    "            # Ses dosyasını oynat\n",
    "            os.system(f\"start {audio_filename}\")  \n",
    "        except Exception as e:\n",
    "            print(f\"Ses dosyası kaydedilemedi: {e}\")\n",
    "    else:\n",
    "        print(\"Sesli yanıt verilemiyor, metin boş.\")\n",
    "\n",
    "def exit_program():\n",
    "    print(\"Teşekkürler! Program kapanıyor...\")\n",
    "    sys.exit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 25 saniye dinle\n",
    "    transcribed_text = listen_from_microphone(duration=25)\n",
    "    \n",
    "    if transcribed_text:\n",
    "        if \"teşekkür\" in transcribed_text.lower():  # Küçük harfe dönüştür\n",
    "            exit_program()\n",
    "        \n",
    "        text_to_speech(transcribed_text)\n",
    "    else:\n",
    "        print(\"Metin alınamadı, sesli yanıt verilemiyor.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80f9e87-c832-4065-a5b0-5b523782623c",
   "metadata": {},
   "source": [
    "# text correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "34f623a8-aa07-4f98-939c-ef72a0463ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Using cached textblob-0.18.0.post0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting nltk>=3.8 (from textblob)\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in c:\\users\\helin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Collecting joblib (from nltk>=3.8->textblob)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\helin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.8->textblob) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\helin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.8->textblob) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\helin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->nltk>=3.8->textblob) (0.4.6)\n",
      "Using cached textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Installing collected packages: joblib, nltk, textblob\n",
      "Successfully installed joblib-1.4.2 nltk-3.9.1 textblob-0.18.0.post0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "95bd4c0e-461f-43f0-acc1-f5d75f386097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 hamburgaer istiyorum anna 1 kolya\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def correct_spelling(text: str) -> str:\n",
    "    blob = TextBlob(text)\n",
    "    return str(blob.correct())\n",
    "\n",
    "# Kullanım\n",
    "user_input = \"2 hamburgaer istiyorum yanina 1 kola\"\n",
    "corrected_input = correct_spelling(user_input)\n",
    "print(corrected_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2986c0b2-921e-4263-a87a-3e02ed302102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting zemberek-python"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached zemberek_python-0.2.3-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting antlr4-python3-runtime==4.8 (from zemberek-python)\n",
      "  Using cached antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\helin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from zemberek-python) (1.26.4)\n",
      "Using cached zemberek_python-0.2.3-py3-none-any.whl (95.1 MB)\n",
      "Building wheels for collected packages: antlr4-python3-runtime\n",
      "  Building wheel for antlr4-python3-runtime (pyproject.toml): started\n",
      "  Building wheel for antlr4-python3-runtime (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141219 sha256=1db495aeac26594637bf7b3d66294fd766c717b83ebbe25a5184500855f64f40\n",
      "  Stored in directory: c:\\users\\helin\\appdata\\local\\pip\\cache\\wheels\\21\\10\\be\\9a70640a3a60ed4a7e1a45e49bb9f58b04692d5d7b517bd39e\n",
      "Successfully built antlr4-python3-runtime\n",
      "Installing collected packages: antlr4-python3-runtime, zemberek-python\n",
      "Successfully installed antlr4-python3-runtime-4.8 zemberek-python-0.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install zemberek-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0f212afc-b289-440c-a0ba-d246a8110d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 20:32:23,007 - zemberek.morphology.turkish_morphology - INFO\n",
      "Msg: TurkishMorphology instance initialized in 8.698110103607178\n",
      "\n",
      "2 hamburgaer istiyorum yanina 1 kola\n"
     ]
    }
   ],
   "source": [
    "from zemberek import TurkishMorphology, TurkishSpellChecker\n",
    "\n",
    "# Türkçe morfolojik analiz için gerekli yapıyı oluşturuyoruz\n",
    "morphology = TurkishMorphology.create_with_defaults()\n",
    "\n",
    "# SpellChecker'ı doğru başlatıyoruz\n",
    "spell_checker = TurkishSpellChecker(morphology)\n",
    "\n",
    "# Yazım düzeltme fonksiyonu\n",
    "def correct_spelling(text: str) -> str:\n",
    "    # Zemberek'teki yazım hatalarını düzeltme işlemi\n",
    "    corrections = spell_checker.suggest_for_word(text)\n",
    "    if corrections:\n",
    "        # İlk öneriyi alıyoruz (en doğru öneri)\n",
    "        return corrections[0].word\n",
    "    return text  # Eğer düzeltme yapılmazsa orijinal metni döndürüyoruz\n",
    "\n",
    "# Kullanım örneği\n",
    "user_input = \"2 hamburgaer istiyorum yanina 1 kola\"\n",
    "corrected_input = correct_spelling(user_input)\n",
    "print(corrected_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "67ade18d-a025-4b59-b50b-51885209fb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 20:35:44,148 - httpx - INFO\n",
      "Msg: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "Düzeltilmiş Metin: Düzgün yazımı: \"2 hamburger istiyorum, yanına 1 kola, ayrıca bir de ızgara tavuk istiyorum.\"\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "# LLM modelini yükleyin (OpenAI GPT-3 örneği)\n",
    "\n",
    "\n",
    "# Yazım düzeltme prompt'u\n",
    "def correct_spelling_with_gpt(text: str) -> str:\n",
    "    prompt = f\"Yazım hatalarını düzelt: '{text}'\"\n",
    "    response = llm(prompt)  # Model cevabını alıyoruz\n",
    "    corrected_text = response.content.strip()  # Yanıtı al ve strip uygula\n",
    "    return corrected_text\n",
    "\n",
    "# Kullanıcıdan gelen yazılı metin\n",
    "user_input = \"2 hamburgaer istiyorum yanina 1 kola ayrica bide izgara tavuk istiyeourm \"\n",
    "corrected_input = correct_spelling_with_gpt(user_input)\n",
    "\n",
    "print(\"Düzeltilmiş Metin:\", corrected_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "94856f79-e8fd-4b23-8afb-838d9c09bd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 20:36:53,285 - httpx - INFO\n",
      "Msg: HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "Düzeltilmiş Metin: \"2 hamburger istiyorum, yanına 1 kola ve bir de ızgara tavuk istiyorum.\"\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "# LLM modelini yükleyin (OpenAI GPT-3 örneği)\n",
    "llm = OpenAI()\n",
    "\n",
    "# Yazım düzeltme prompt'u\n",
    "def correct_spelling_with_gpt(text: str) -> str:\n",
    "    prompt = f\"Yazım hatalarını düzelt: '{text}'\"\n",
    "    response = llm(prompt)  # Model cevabını alıyoruz\n",
    "    corrected_text = response.strip()  # Yanıtın metin kısmını al ve strip uygula\n",
    "    return corrected_text\n",
    "\n",
    "# Kullanıcıdan gelen yazılı metin\n",
    "user_input = \"2 hamburgaer istiyorum yanina 1 kola ayrica bide izgara tavuk istiyeourm \"\n",
    "corrected_input = correct_spelling_with_gpt(user_input)\n",
    "\n",
    "print(\"Düzeltilmiş Metin:\", corrected_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c8ffae08-e062-4b04-9f27-48cd49afd1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 20:37:37,683 - httpx - INFO\n",
      "Msg: HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "Düzeltilmiş Metin: \"2 hamburger istiyorum, yanına 1 kola, ayrıca bir de ızgara tavuk istiyorum.\"\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "# LLM modelini yükleyin (OpenAI GPT-3 örneği)\n",
    "llm = OpenAI()\n",
    "\n",
    "# Yazım düzeltme prompt'u\n",
    "def correct_spelling_with_gpt(text: str) -> str:\n",
    "    prompt = f\"Yazım hatalarını düzelt: '{text}'\"\n",
    "    response = llm(prompt)  # Model cevabını alıyoruz\n",
    "    \n",
    "    # Eğer response bir liste veya nesne ise, metni çıkar\n",
    "    corrected_text = response[0].text.strip() if isinstance(response, list) else response.strip()\n",
    "    \n",
    "    \n",
    "    return corrected_text\n",
    "\n",
    "# Kullanıcıdan gelen yazılı metin\n",
    "user_input = \"2 hamburgaer istiyorum yanina 1 kola ayrica bide izgara tavuk istiyeourm \"\n",
    "corrected_input = correct_spelling_with_gpt(user_input)\n",
    "\n",
    "print(\"Düzeltilmiş Metin:\", corrected_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567d79b4-f361-4b1c-bdd2-9f965ca2c84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c43373-85bb-4011-963d-e2cb7dbff84e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3aa954-c178-4370-97b9-aed435935f22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cac220-b805-4fb3-ac05-0d12d1c53436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cceb45b-cfa1-4202-b75a-f7ccfe2c9969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ebfde7-23b5-4092-8d3e-3d7ae1d3595d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d9f006-f614-4c99-89b6-842a4c9bbdd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f531f3-0458-49f1-9242-9a1b93421458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
