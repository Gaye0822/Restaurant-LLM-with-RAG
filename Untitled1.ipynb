{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9110113-9156-46ff-a35a-399f8dc47503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from pathlib import Path\n",
    "from langchain_openai import ChatOpenAI,OpenAIEmbeddings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.agents import Tool, AgentExecutor, ConversationalAgent\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain import OpenAI, LLMChain\n",
    "from langchain.chains import RetrievalQA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccbff2b0-adeb-4cd6-9736-ee12da349139",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dba04e2-a5bd-411f-bd31-225d6fdc6d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c159527-38de-49cf-8253-a3c55d568657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kategori</th>\n",
       "      <th>urun</th>\n",
       "      <th>?cindekiler</th>\n",
       "      <th>Fiyat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baslangiclar</td>\n",
       "      <td>Nachos</td>\n",
       "      <td>El yapimi tortilla cips, cheddar, yesil sogan,...</td>\n",
       "      <td>120 TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baslangiclar</td>\n",
       "      <td>Mozzarella cubuklari</td>\n",
       "      <td>Pane mozzarella cubuklari, pesto sos</td>\n",
       "      <td>115 TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baslangiclar</td>\n",
       "      <td>Tavuk Kanatlari</td>\n",
       "      <td>Pane tavuk kanatlari; sos secenekleri: BBQ, ha...</td>\n",
       "      <td>125 TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baslangiclar</td>\n",
       "      <td>Karides Tava</td>\n",
       "      <td>Jumbo karides, sarimsak, tereyagi, limon suyu,...</td>\n",
       "      <td>150 TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baslangiclar</td>\n",
       "      <td>Falafel Tabagi</td>\n",
       "      <td>Falafel koftesi, humus, tahin sos, salata</td>\n",
       "      <td>75 TL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Kategori                  urun  \\\n",
       "0  Baslangiclar                Nachos   \n",
       "1  Baslangiclar  Mozzarella cubuklari   \n",
       "2  Baslangiclar       Tavuk Kanatlari   \n",
       "3  Baslangiclar          Karides Tava   \n",
       "4  Baslangiclar        Falafel Tabagi   \n",
       "\n",
       "                                         ?cindekiler   Fiyat  \n",
       "0  El yapimi tortilla cips, cheddar, yesil sogan,...  120 TL  \n",
       "1               Pane mozzarella cubuklari, pesto sos  115 TL  \n",
       "2  Pane tavuk kanatlari; sos secenekleri: BBQ, ha...  125 TL  \n",
       "3  Jumbo karides, sarimsak, tereyagi, limon suyu,...  150 TL  \n",
       "4          Falafel koftesi, humus, tahin sos, salata   75 TL  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = ('menu1.csv') # insert the path of the csv file\n",
    "data = pd.read_csv(file_path,sep=';')\n",
    "\n",
    "#preview the csv file\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59bf77ff-c745-4733-8055-cd52b47ef066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mozzarella cubuklari'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.urun[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b93ebfa1-5124-4f32-8517-3679e70b6f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Nachos', 'Mozzarella cubuklari', 'Tavuk Kanatlari',\n",
       "       'Karides Tava', 'Falafel Tabagi', 'Sebzeli Spring Roll',\n",
       "       'Mercimek corbasi', 'Kremali Mantar corbasi', 'Domates corbasi',\n",
       "       'Tavuk Suyu corbasi', 'Balkabagi corbasi', 'Peynirli Tavuk Pizza',\n",
       "       'Etli Pizza', 'Vegan Pizza', 'Acili Deniz Pizza',\n",
       "       'Margarita Pizza', 'Klasik Burger', 'Cheeseburger', 'Siyah Burger',\n",
       "       'Tavuk Burger', 'Acili Burger', 'izgara Tavuk', 'Antrikot',\n",
       "       'Somon izgara', 'Sebzeli Guvec', 'Sufle', 'Tiramisu', 'Cheesecake',\n",
       "       'Firin Sutlac', nan], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.urun.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62a3ff50-324a-4d2b-8f97-af49f8ef14c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader(file_path=file_path)\n",
    "docs = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abd7989b-7e92-4265-8222-a1add9c0cb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "index = faiss.IndexFlatL2(len(OpenAIEmbeddings().embed_query(\" \")))\n",
    "vector_store = FAISS(\n",
    "    embedding_function=OpenAIEmbeddings(),\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f6e330f-6c69-4f12-a4e2-493c223dcdfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['29b1373b-f695-4163-8874-b16ec1181e92',\n",
       " 'ec9156fa-3303-485b-9753-ac6138a8e7c6',\n",
       " '57510c82-0e5c-4c0e-a405-c51b08d0ecd1',\n",
       " '0dc0f0bc-0d40-4a43-aec2-42e646d704dc',\n",
       " '2fa34b6d-5eae-4f04-87c3-b1734a7255b0',\n",
       " 'fa1fe142-4c63-48c8-a4f4-23e2fecae79c',\n",
       " '72efbff9-8f5c-49a9-b32b-77728f80c8e7',\n",
       " '1dc4c28a-5f1b-4b45-a3d4-8f0e4f2d67ae',\n",
       " 'b5dac95b-1630-4706-af91-ced4142bd2a0',\n",
       " '219dcec4-a57e-4abb-8953-a322201c0fe2',\n",
       " 'ca50fb38-e617-4db5-a744-d05e260116a8',\n",
       " 'b2e1cf5c-1c3a-4b22-98a8-42bfae24e935',\n",
       " '82fc7ca5-da14-4e13-a1f8-8f3abc3a264b',\n",
       " '235c06d9-0bc4-44e2-b85b-586cca36dae4',\n",
       " 'd2963668-76d6-426d-9260-6fed02c4fb10',\n",
       " 'b2989a00-850b-42fb-a5fd-d83845be7915',\n",
       " '28dbb85f-5808-49d4-84c1-8e7b01f7ad0a',\n",
       " '19275246-a2d8-4cb7-bfc9-268bb70b1ca1',\n",
       " 'fce4e4cb-5bb7-4738-81e5-da23f2afc65d',\n",
       " '3dd99d54-e057-4d71-86b2-ea98231a6cca',\n",
       " '877ab861-7584-4b01-8820-dd91cce6e90a',\n",
       " 'cdae47ee-81b7-40a6-a59f-cab8cbac0e3a',\n",
       " '0f24c1ef-7e02-4db5-a4c4-714a9a4c60db',\n",
       " 'd09e58a6-a993-43db-bdc9-9a4fa7ba99c8',\n",
       " '7886d772-e649-4c94-9185-58a79b0d754b',\n",
       " '2e6e1c88-ca1d-4e60-bae3-8b549a36d3d1',\n",
       " 'd2056de5-0fc1-4f7e-a9e4-3ef1e36d13b3',\n",
       " 'b49eec71-479a-4c5f-a6ab-f034aecf2985',\n",
       " '15ad2a8b-f3dd-47bb-9ff3-f675cfebf901',\n",
       " '106cf618-de09-4601-8148-fa9ff498c053',\n",
       " 'c5c21208-2a17-4d07-9dc5-8f1392490f97',\n",
       " '580fddf7-04d0-4ce1-b423-1ec94e208583',\n",
       " 'bd38534d-c324-4517-a30f-626dd6728083',\n",
       " '1d13832c-cfe0-4eb3-b326-aaf7fb91c735',\n",
       " '5051e412-eac6-4f71-a52c-af4cf1a9c0b1',\n",
       " '2bed7c4a-3dd9-46b7-a6c1-4689924a4578',\n",
       " 'ae913cdc-1f46-4bba-a26a-aa810b82eeca',\n",
       " '7125dc18-8500-4d6f-afbc-eb0f5c260ba0',\n",
       " '7af1fa9e-1e1c-47ca-852e-5a11c2e1e202',\n",
       " '0dd105fe-68a5-4273-9a15-b455b68ffa48']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(documents=docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa11a26b-2271-48cb-848a-81f9d06882e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c734f939-cb78-4a99-b1d9-5afe28d7c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationStringBufferMemory\n",
    "from langchain.chains import RetrievalQA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9aad3b3-f7bb-4e34-b0a4-9d244af0d39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9bd904ed-c5cf-4330-b7bf-fc34295b0ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are a waiter for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know.if the item is not in the menu say that the item is not available .And dont reccommend anythin outside the menu youve recieved. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", system_prompt),  # Add system prompt here\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the question-answer chain\n",
    "#question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9df0ce36-f0f7-4004-97f0-101840f0c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List ,Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "class sip(TypedDict):\n",
    "    \"\"\"Represents a sentence describing an ordered item.\"\"\"\n",
    "\n",
    "    sip_name: Annotated[str, ..., \"Name of the ordered item, such as a menu item.\"]\n",
    "    sip_count: Annotated[int, ..., \"Quantity of the ordered item.\"]\n",
    "\n",
    "class non_sip(TypedDict):\n",
    "    \"\"\"Represents a sentence describing a non-ordered item.\"\"\"\n",
    "\n",
    "    non_sip_name: Annotated[str, ..., \"Name of the item, without an order (e.g., general reference to a thing or asking questions about it).\"]\n",
    "    non_sip_count: Annotated[int, ..., \"Count of the item, if mentioned, but not part of an order.\"]\n",
    "\n",
    "class del_item(TypedDict):\n",
    "    \"\"\"Represents a sentence describing an item to be deleted from the order.\"\"\"\n",
    "    \n",
    "    del_name: Annotated[str, ..., \"Name of the ordered item that is being canceled or removed.\"]\n",
    "    del_count: Annotated[int, ..., \"Quantity of the item that is being canceled or removed. This value can be positive or indicate the total amount to be canceled.\"]\n",
    "    is_all: Annotated[Optional[bool], \"Indicates if the entire item category (e.g., all 'hamburgers') is being canceled. 'True' means all instances of that item will be canceled, 'False' means just a specific quantity or instance.\"]\n",
    "    description: Annotated[Optional[str], \"Describes the user's intent to cancel all instances of a specific item category, like 'hamburgers', without providing a specific count. This could include phrases like 'I want to cancel all hamburgers'.\"]\n",
    "\n",
    "class FinalResponse(BaseModel):\n",
    "    final_output: List[Union[sip, non_sip, del_item]]\n",
    "\n",
    "# Example of structured output model usage\n",
    "structured_llm = llm.with_structured_output(FinalResponse)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f5fc58-698f-4d86-b3ec-bd2684701950",
   "metadata": {},
   "source": [
    "# MODELİN ERİLEN CEVAPLARI AYIKLAMASI YERİNE İNPUTU DİCT HALİNE DÖNÜŞTÜRMESİNİ SAĞLIYORUZ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbc1a262-eca2-4fbb-ab1c-7df50dd83cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "system1 = \"\"\"You are an expert at converting user questions into database queries. \\\n",
    "customers will talk you about the menu and you will tke the order or answer their questions \\\n",
    "you have to understand the input for deciding to take an order or answer the question \\\n",
    "if you dont understand the meaning of a sentence or the intent tell it \"\"\"\n",
    "\n",
    "prompt1 = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system1),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a2f9322-0479-4285-a1ba-4883a8049360",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm1 = llm.with_structured_output(FinalResponse)\n",
    "query_analyzer = prompt1 | structured_llm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60fa9fa-85fc-4cc4-ab6e-7e794a821a46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b314895d-f258-40f6-bd4b-3ceb7a4d1ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalResponse(final_output=[{'sip_name': 'çay', 'sip_count': 2}])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyzer.invoke(\"bana iki çay yolla \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97873046-d88d-44a2-90b8-5d2c1f5b117d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalResponse(final_output=[{'sip_name': 'latte', 'sip_count': 2}])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyzer.invoke(\"2 latte alabilir miyim \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "439416cc-2244-4157-832f-2ba6890ca9d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalResponse(final_output=[{'non_sip_name': 'Menü', 'non_sip_count': 1}])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyzer.invoke(\"menüde neler var\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09b5d772-ae77-4b17-93c6-51d6d7cab391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalResponse(final_output=[{'sip_name': 'latte', 'sip_count': 2}])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyzer.invoke(\"2 latte alabilir miyim \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7bfca282-88ee-44f5-85e7-25f7bd41464a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalResponse(final_output=[{'non_sip_name': 'makarna tarifi', 'non_sip_count': 1}])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyzer.invoke(\"makarnayı nasıl yapıyosunuz \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa5a22e9-a17b-4f40-9d22-1ad637dff215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalResponse(final_output=[{'non_sip_name': 'acılı biftek', 'non_sip_count': 1}])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyzer.invoke(\"acılı biftek ne kadar acı\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d94fafa-195f-41bd-a24d-f87fa5c75ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalResponse(final_output=[{'sip_name': 'pizza', 'sip_count': 1}, {'del_name': 'acı biber', 'del_count': 1, 'is_all': True, 'description': 'pizza içindeki acı biberler'}])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyzer.invoke(\"eğer içindeki acı biberleri çıkartırsanız pizza almak istiyorum \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38fbc434-41c2-47d2-b4ad-72325561d3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalResponse(final_output=[{'non_sip_name': 'latte', 'non_sip_count': 1}])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyzer.invoke(\"latteyi laktozsuz süt ile mi yapıyorsunuz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "908b73c7-5a75-474b-ae8e-3b1ca68f0fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalResponse(final_output=[{'sip_name': 'keikli', 'sip_count': 2}, {'sip_name': 'kremalı makarna', 'sip_count': 1}])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyzer.invoke(\"2 keikli 1 de kremalı makarna istiyorum \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed362e6a-b615-4c9a-a843-7e885e92d58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalResponse(final_output=[{'sip_name': 'hamburger', 'sip_count': 2}, {'sip_name': 'kola', 'sip_count': 1}])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyzer.invoke(\"2 hamburger istiyorum yanına 1 kola \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bca68cbb-da4a-4da5-899a-52608a97668f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalResponse(final_output=[{'del_name': 'pizza', 'del_count': 1, 'is_all': None, 'description': None}])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyzer.invoke(\"1 pizzayı silelim \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad95c649-29ca-41cc-a36e-a6bcfb94f954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalResponse(final_output=[{'del_name': 'hamburger', 'del_count': 1, 'is_all': None, 'description': None}])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyzer.invoke(\"hamburgerlerden vazgeçtim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f12634-da15-4cc5-a70c-8b69b6becb10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15c2c43-259b-40fb-a754-cc6622917c95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107622db-c144-47e8-bc79-770a44ae81f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97d10d87-578f-47a0-9b4f-1828fd35440a",
   "metadata": {},
   "source": [
    "# ayıklanmış itemlere menü kontrolü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b9f1390-f60d-412f-a54a-ea4f7f122b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sip_in_menu(final_response: FinalResponse, data: pd.DataFrame) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Checks if `sip` items in the FinalResponse exist in the `urun` column of the menu DataFrame.\n",
    "\n",
    "    :param final_response: FinalResponse object containing the structured output.\n",
    "    :param menu_data: pandas DataFrame containing the menu with a `urun` column.\n",
    "    :return: List of results with each `sip` item and its existence status.\n",
    "    \"\"\"\n",
    "    # 'urun' sütunundaki benzersiz ürünleri al\n",
    "    menu_items = set(data['urun'].str.lower().unique())\n",
    "    \n",
    "    # Sonuçları tutmak için liste\n",
    "    results = []\n",
    "\n",
    "    # FinalResponse içindeki `sip` nesnelerini kontrol et\n",
    "    for item in final_response.final_output:\n",
    "        if isinstance(item, dict) and \"sip_name\" in item:\n",
    "            sip_name_lower = item[\"sip_name\"].lower()\n",
    "            exists = sip_name_lower in menu_items\n",
    "            results.append({\n",
    "                \"sip_name\": item[\"sip_name\"],\n",
    "                \"sip_count\": item[\"sip_count\"],\n",
    "                \"exists_in_menu\": exists\n",
    "            })\n",
    "        else:\n",
    "             results.append({\n",
    "                \"non_sip_name\": item[\"non_sip_name\"],\n",
    "                \"non_sip_count\": item[\"non_sip_count\"]})\n",
    "             \n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39ca8fac-3cf2-4bf6-b581-2bc01c415f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sip_name': 'Karides tava', 'sip_count': 2, 'exists_in_menu': True}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_sip_in_menu(final_response=FinalResponse(final_output=[{'sip_name': 'Karides tava', 'sip_count': 2}]),data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f074b2e-6efe-494c-ae20-c50817643422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sip_name': 'hamburger', 'sip_count': 2, 'exists_in_menu': False},\n",
       " {'sip_name': 'kola', 'sip_count': 1, 'exists_in_menu': False}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_sip_in_menu(final_response=query_analyzer.invoke(\"2 hamburger istiyorum yanına 1 kola \"),data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6358d5ec-e118-40e8-999d-2578a2478755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sip_name': 'NACHOS', 'sip_count': 2, 'exists_in_menu': True}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quest=query_analyzer.invoke(\"2 NACHOS istiyorum\")\n",
    "check_sip_in_menu(final_response=quest,data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46296d91-ec6a-4a73-98dd-9d4dc2b727d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sip_name': 'izgara tavuk', 'sip_count': 2, 'exists_in_menu': True}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quest=query_analyzer.invoke(\"2 izgara tavuk istiyorum\")\n",
    "check_sip_in_menu(final_response=quest,data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1391986d-be5a-4646-a463-6a1df233a811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'non_sip_name': 'Mozarella Pizza İçindekiler', 'non_sip_count': 1}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quest=query_analyzer.invoke(\"mozarella pizzanın içinde ne var \")\n",
    "check_sip_in_menu(final_response=quest,data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb0d0197-3464-4eb6-98d8-149472fe67ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/04/nhwvkmt13753zn37rgwn35zr0000gn/T/ipykernel_49477/3353824168.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e978700a-b33f-4343-99ad-baadddd8b34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    input_key=\"query\",\n",
    "    return_source_documents=False,\n",
    "    memory=memory  # Hafızayı buraya ekliyoruz\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c6464b-303a-4852-9fee-b021a07e8d86",
   "metadata": {},
   "source": [
    "# iki zinciri birlikte çağırma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f0a3efe-1d2c-48aa-ad75-bf9c117cceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_conversation(query: str):\n",
    "    # RAG zincirinden yanıt alıyoruz\n",
    "    rag_output = rag_chain.invoke({\"query\": query})\n",
    "\n",
    "    quest=query_analyzer.invoke({\"query\": query})\n",
    "\n",
    "\n",
    "    # check_sip_in_menu fonksiyonunu çalıştırıyoruz\n",
    "    sip_check_result = check_sip_in_menu(quest, data)\n",
    "\n",
    "    # Hem RAG çıktısını hem de sip kontrolünü döndürüyoruz\n",
    "    return {\n",
    "        \"rag_response\": rag_output,\n",
    "        \"sip_check_result\": sip_check_result\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7fb87b63-a548-4a04-836e-bb2cb1db53d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Response: {'query': '2 nachos istiyorum', 'chat_history': [HumanMessage(content='2 nachos istiyorum', additional_kwargs={}, response_metadata={}), AIMessage(content='İki nachos sipariş etmek isterseniz, toplam fiyat 240 TL olacaktır (120 TL x 2). Siparişinizi nasıl almak istersiniz?', additional_kwargs={}, response_metadata={})], 'result': 'İki nachos sipariş etmek isterseniz, toplam fiyat 240 TL olacaktır (120 TL x 2). Siparişinizi nasıl almak istersiniz?'}\n",
      "Sip Check Result: [{'sip_name': 'nachos', 'sip_count': 2, 'exists_in_menu': True}]\n"
     ]
    }
   ],
   "source": [
    "query = \"2 nachos istiyorum\"\n",
    "output = run_conversation(query)\n",
    "\n",
    "# Sonuçları yazdırıyoruz\n",
    "print(\"RAG Response:\", output['rag_response'])\n",
    "print(\"Sip Check Result:\", output['sip_check_result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a3044ce4-00da-40ef-b107-14bec7132644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_spelling_with_gpt(text: str) -> str:\n",
    "    prompt = f\"Yazım hatalarını düzelt: '{text}'\"\n",
    "    response = llm(prompt)  # Model cevabını alıyoruz\n",
    "\n",
    "    # Yanıtın türünü kontrol ediyoruz\n",
    "    print(type(response))  # Yanıtın türünü öğrenin\n",
    "    print(response)        # Yanıtı yazdırarak yapısını görün\n",
    "\n",
    "    # AIMessage objesinin doğru özelliğine erişim (Örneğin, 'content' olabilir)\n",
    "    if hasattr(response, 'text'):  # Eğer 'text' özelliği varsa\n",
    "        corrected_text = response.text.strip()\n",
    "    elif hasattr(response, 'content'):  # 'content' özelliği varsa\n",
    "        corrected_text = response.content.strip()\n",
    "    else:\n",
    "        corrected_text = str(response).strip()  # Eğer başka bir formatta ise, string olarak al\n",
    "\n",
    "    return corrected_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5851c40-3db2-45c4-a3eb-9f241060df13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9c428ce-aade-4653-b5f0-442918085b3d",
   "metadata": {},
   "source": [
    "# sonsuz döngü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5c06be07-e68d-4280-b910-ceb0b0842381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Soru (exit yazarsanız çıkılır):  pizza çeşitlerinş nelerdir \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid input type <class 'langchain_core.prompts.chat.ChatPromptTemplate'>. Must be a PromptValue, str, or list of BaseMessages.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSipariş Durumu:\u001b[39m\u001b[38;5;124m\"\u001b[39m, sip_check_result)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Konuşma başlatma\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m \u001b[43mrun_conversation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[57], line 24\u001b[0m, in \u001b[0;36mrun_conversation\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSiparişleriniz iptal edildi.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Konuşmayı sonlandırıyoruz\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m corrected_query \u001b[38;5;241m=\u001b[39m \u001b[43mcorrect_spelling_with_gpt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDüzeltilmiş Soru: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrected_query\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# RAG zincirinden yanıt alıyoruz\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[56], line 3\u001b[0m, in \u001b[0;36mcorrect_spelling_with_gpt\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcorrect_spelling_with_gpt\u001b[39m(text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m      2\u001b[0m     prompt3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYazım hatalarını düzelt: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Model cevabını alıyoruz\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Yanıtın türünü kontrol ediyoruz\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(response))  \u001b[38;5;66;03m# Yanıtın türünü öğrenin\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     emit_warning()\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1017\u001b[0m, in \u001b[0;36mBaseChatModel.__call__\u001b[0;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;129m@deprecated\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.1.7\u001b[39m\u001b[38;5;124m\"\u001b[39m, alternative\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvoke\u001b[39m\u001b[38;5;124m\"\u001b[39m, removal\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1015\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1016\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m-> 1017\u001b[0m     generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1020\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(generation, ChatGeneration):\n\u001b[1;32m   1021\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:643\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    642\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    644\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    645\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    647\u001b[0m ]\n\u001b[1;32m    648\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:633\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 633\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    639\u001b[0m         )\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:851\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 851\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:692\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m     stream_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(\n\u001b[1;32m    689\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    690\u001b[0m     )\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generate_from_stream(stream_iter)\n\u001b[0;32m--> 692\u001b[0m payload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_request_payload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    693\u001b[0m generation_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m payload:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:717\u001b[0m, in \u001b[0;36mBaseChatOpenAI._get_request_payload\u001b[0;34m(self, input_, stop, **kwargs)\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_request_payload\u001b[39m(\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    712\u001b[0m     input_: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    716\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 717\u001b[0m     messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_messages()\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m stop\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:273\u001b[0m, in \u001b[0;36mBaseChatModel._convert_input\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    270\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28minput\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    271\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust be a PromptValue, str, or list of BaseMessages.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    272\u001b[0m     )\n\u001b[0;32m--> 273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid input type <class 'langchain_core.prompts.chat.ChatPromptTemplate'>. Must be a PromptValue, str, or list of BaseMessages."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Sonsuz döngü\n",
    "def run_conversation():\n",
    "    order_history =[]\n",
    "\n",
    "    while True:\n",
    "        # Kullanıcıdan soru alıyoruz\n",
    "        query = input(\"Soru (exit yazarsanız çıkılır): \")\n",
    "\n",
    "        # 'exit' komutu ile çıkış\n",
    "        if query.lower() == \"exit\":\n",
    "            if order_history:\n",
    "                print(\"Siparişleriniz:\", order_history)\n",
    "                confirmation = input(\"Onaylıyor musunuz? (Evet/Hayır): \")\n",
    "                if confirmation.lower() == \"evet\":\n",
    "                    # Siparişleri bir .txt dosyasına kaydediyoruz\n",
    "                    with open(\"siparisler.txt\", \"w\") as f:\n",
    "                        for item in order_history:\n",
    "                            f.write(f\"{item['sip_name']} x {item['sip_count']}\\n\")\n",
    "                    print(\"Siparişleriniz kaydedildi.\")\n",
    "                else:\n",
    "                    print(\"Siparişleriniz iptal edildi.\")\n",
    "            break  # Konuşmayı sonlandırıyoruz\n",
    "\n",
    "        corrected_query = correct_spelling_with_gpt(query)\n",
    "        print(f\"Düzeltilmiş Soru: {corrected_query}\")\n",
    "\n",
    "\n",
    "        # RAG zincirinden yanıt alıyoruz\n",
    "        rag_output = rag_chain.invoke({\"query\": corrected_query})\n",
    "        print(\"RAG Yanıtı:\", rag_output[\"result\"])\n",
    "\n",
    "        quest=query_analyzer.invoke({\"query\": corrected_query})\n",
    "\n",
    "\n",
    "    # check_sip_in_menu fonksiyonunu çalıştırıyoruz\n",
    "        sip_check_result = check_sip_in_menu(quest, data)\n",
    "\n",
    "        # Siparişi hafızada tutuyoruz, eğer ürün menüde varsa\n",
    "        for result in sip_check_result:\n",
    "            if result.get(\"exists_in_menu\", True):\n",
    "                order_history.append(result)\n",
    "\n",
    "        # Kullanıcıya yanıt veriyoruz\n",
    "        \n",
    "        print(\"Sipariş Durumu:\", sip_check_result)\n",
    "\n",
    "# Konuşma başlatma\n",
    "run_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4b545f-4d84-4360-bf7a-29cee73dd5ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a6e712e-ae42-4280-a15a-e531e93f3b63",
   "metadata": {},
   "source": [
    "# voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad172d5-ba70-4a3d-911b-bba6bf5f7442",
   "metadata": {},
   "outputs": [],
   "source": [
    "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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "03d8bf09-4bef-4405-b87f-2429ce6da2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import wave\n",
    "import io\n",
    "from gtts import gTTS\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8fb81f07-bca7-4f9d-a584-5078cdacff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_API_URL = 'https://api.groq.com/openai/v1/audio/transcriptions'\n",
    "API_KEY = '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'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "900fa14a-6524-4ca5-a0c6-9025ddebfa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio(duration=5, samplerate=16000):\n",
    "    print(\"Recording...\")\n",
    "    audio_data = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1, dtype='int16')\n",
    "    sd.wait()\n",
    "    return audio_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0f460931-a7f7-4080-b7ca-a1cd96fba917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_audio(audio_data, filename='audio.wav'):\n",
    "    with wave.open(filename, 'wb') as wf:\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(2)  # 2 bytes per sample for int16\n",
    "        wf.setframerate(16000)\n",
    "        wf.writeframes(audio_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "82753bf8-4b0c-4a89-8e6e-d90bbe3c3319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_audio(audio_data, filename='audio.wav'):\n",
    "    with wave.open(filename, 'wb') as wf:\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(2)  # 2 bytes per sample for int16\n",
    "        wf.setframerate(16000)\n",
    "        wf.writeframes(audio_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4c20fa73-b81d-4819-8f36-e6a6c56fc792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio_groq(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        audio_data = f.read()\n",
    "\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {API_KEY}',\n",
    "    }\n",
    "\n",
    "    files = {\n",
    "        'file': (filename, audio_data),\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        'model': 'whisper-large-v3',\n",
    "    }\n",
    "\n",
    "    response = requests.post(GROQ_API_URL, headers=headers, files=files, data=data)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        return result.get('transcription', 'Error: No transcription found')\n",
    "    else:\n",
    "        return f\"Error: {response.text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "924d2901-2e33-4047-9a90-f29409887708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: {\"text\":\" Herhalde orada takılı kaldı o. Gayet yukarıda. Dur bir dakika. O diyor.\",\"x_groq\":{\"id\":\"req_01je6dadx1ftn9a42eyx1pvn76\"}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def transcribe_audio(filename):\n",
    "    # Open the audio file in binary mode\n",
    "    with open(filename, 'rb') as f:\n",
    "        audio_data = f.read()\n",
    "\n",
    "    # Create the API endpoint URL\n",
    "    url = \"https://api.groq.com/openai/v1/audio/transcriptions\"\n",
    "\n",
    "    # Prepare the payload and headers for the request\n",
    "    headers = {\n",
    "        \"Authorization\": f'Bearer {API_KEY}'\n",
    "    }\n",
    "    \n",
    "    files = {\n",
    "        'file': ('audio.wav', audio_data, 'audio/wav')\n",
    "    }\n",
    "    data = {\n",
    "    'model': 'whisper-large-v3',\n",
    "    'language': 'tr'\n",
    "}\n",
    "    \n",
    "    # Send the POST request\n",
    "    response = requests.post(url, headers=headers, files=files,data=data)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        return response.text\n",
    "    else:\n",
    "        return f\"Error: {response.text}\"\n",
    "\n",
    "# Example usage\n",
    "transcription = transcribe_audio('audio.wav')\n",
    "print(f\"Transcription: {transcription}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6e618b5c-1488-4567-bfa8-228e18b91d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_speech(text):\n",
    "    tts = gTTS(text, lang='tr')\n",
    "    tts.save(\"response.mp3\")\n",
    "    os.system(\"afplay response.mp3\")  # On macOS, use 'afplay response.mp3'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "56c812d0-d30e-4383-a868-e6014322cc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something...\n",
      "Recording...\n",
      "Transcription: {\"text\":\" Pizza çeşitleriniz nelerdir?\",\"x_groq\":{\"id\":\"req_01je6dhamjfw2rp81gwjzqkvjk\"}}\n",
      "\n",
      "RAG Yanıtı: Pizza çeşitlerimiz şunlardır:\n",
      "\n",
      "1. Peynirli Tavuk Pizza - Fiyat: 110 TL\n",
      "   - İçindekiler: Tavuk, cheddar, rokfor, mantar, sarımsak sos\n",
      "\n",
      "2. Etli Pizza - Fiyat: 145 TL\n",
      "   - İçindekiler: Jambon, tavuk, bacon, mozzarella, beyaz sos\n",
      "\n",
      "3. Margarita Pizza - Fiyat: 85 TL\n",
      "   - İçindekiler: Domates, mozzarella, fesleğen, zeytinyağı\n",
      "\n",
      "4. Acili Deniz Pizza - Fiyat: 145 TL\n",
      "   - İçindekiler: Karides, somon, domates, mozzarella, beyaz sos\n",
      "Sipariş Durumu: [{'non_sip_name': 'Pizza çeşitleri', 'non_sip_count': 1}]\n",
      "Say something...\n",
      "Recording...\n",
      "Transcription: {\"text\":\" Margarita pizza almak istiyorum\",\"x_groq\":{\"id\":\"req_01je6dkptpetbbgcjpfgdvxm38\"}}\n",
      "\n",
      "RAG Yanıtı: Margarita Pizza fiyatı 85 TL'dir. Almak istediğinizde bu fiyat üzerinden işlem yapabilirsiniz.\n",
      "Sipariş Durumu: [{'sip_name': 'Margarita pizza', 'sip_count': 1, 'exists_in_menu': True}]\n",
      "Say something...\n",
      "Recording...\n",
      "Transcription: {\"text\":\" Ben istediğim zaten.\",\"x_groq\":{\"id\":\"req_01je6dmaeefwp9q8h6qm5pd53g\"}}\n",
      "\n",
      "RAG Yanıtı: Bu durumda neyin istendiğini belirtmediğiniz için yardımcı olamıyorum. Daha fazla bilgi verirseniz, size yardımcı olmaya çalışabilirim.\n",
      "Sipariş Durumu: [{'non_sip_name': 'Ben istediğim zaten.', 'non_sip_count': 1}]\n",
      "Say something...\n",
      "Recording...\n",
      "Transcription: {\"text\":\" Tatlı olarak ne var?\",\"x_groq\":{\"id\":\"req_01je6dn035fbnvskweszgz757a\"}}\n",
      "\n",
      "RAG Yanıtı: Tatlı olarak şu seçenekler var:\n",
      "\n",
      "1. Sufle - Fiyat: 65 TL (İçindekiler: Belçika çikolatası, tereyağı, un, yumurta)\n",
      "2. Cheesecake - Fiyat: 80 TL (İçindekiler: Krema peynir, bisküvi tabanı, meyve sosu)\n",
      "3. Tiramisu - Fiyat: 85 TL (İçindekiler: Mascarpone, espresso, özel bisküvi)\n",
      "Sipariş Durumu: [{'non_sip_name': 'Tatlı', 'non_sip_count': 1}]\n",
      "Say something...\n",
      "Recording...\n",
      "Transcription: {\"text\":\" Garson ne diyorsa onu yapmamız lazım. Tamam. O TL'yi de tanımlamak.\",\"x_groq\":{\"id\":\"req_01je6dpp14evbsaj41zckv6trj\"}}\n",
      "\n",
      "RAG Yanıtı: Bu bağlamda, \"TL\" muhtemelen Türk Lirası'nın kısaltmasıdır. Garsonun söylediklerini uygulamak ve fiyata uygun bir şekilde hareket etmek gerektiğini belirtiyor. Başka bir sorunuz var mı?\n",
      "Sipariş Durumu: []\n",
      "Say something...\n",
      "Recording...\n",
      "Transcription: {\"text\":\" Çıkış Siparişi göster dememiz lazım.\",\"x_groq\":{\"id\":\"req_01je6dqhmzfc5ar5mh1aqrd468\"}}\n",
      "\n",
      "RAG Yanıtı: Üzgünüm, bu konuda bilgiye sahip değilim.\n",
      "Sipariş Durumu: [{'non_sip_name': 'Çıkış Siparişi', 'non_sip_count': 1}]\n",
      "Say something...\n",
      "Recording...\n",
      "Transcription: {\"text\":\" bir rapor verecek. Hemen sipariş yani sipariş bir peşindeyiz.\",\"x_groq\":{\"id\":\"req_01je6dr074fc6spdapm40cem3n\"}}\n",
      "\n",
      "RAG Yanıtı: Bu isteğe uygun bir cevap veremiyorum. Daha fazla bilgi verirsen yardımcı olmaya çalışabilirim.\n",
      "Sipariş Durumu: [{'sip_name': 'sipariş', 'sip_count': 1, 'exists_in_menu': False}]\n",
      "Say something...\n",
      "Recording...\n",
      "Transcription: {\"text\":\" Evet. Nasıl?\",\"x_groq\":{\"id\":\"req_01je6drjg0evvtgy7457kvy3w7\"}}\n",
      "\n",
      "RAG Yanıtı: Bununla ilgili bir bilgiye sahip değilim.\n",
      "Sipariş Durumu: []\n",
      "Say something...\n",
      "Recording...\n",
      "Transcription: {\"text\":\" Evet. Konuşamıyorum.\",\"x_groq\":{\"id\":\"req_01je6drzepevzv21ebmc98wqw3\"}}\n",
      "\n",
      "RAG Yanıtı: Bununla ilgili bir bilgiye sahip değilim.\n",
      "Sipariş Durumu: []\n",
      "Say something...\n",
      "Recording...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m         text_to_speech(rag_output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Start the conversation\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m \u001b[43mrun_conversation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[73], line 5\u001b[0m, in \u001b[0;36mrun_conversation\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSay something...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     audio_data \u001b[38;5;241m=\u001b[39m \u001b[43mrecord_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     save_audio(audio_data)\n\u001b[1;32m      8\u001b[0m     transcription \u001b[38;5;241m=\u001b[39m transcribe_audio(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio.wav\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[64], line 4\u001b[0m, in \u001b[0;36mrecord_audio\u001b[0;34m(duration, samplerate)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecording...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m audio_data \u001b[38;5;241m=\u001b[39m sd\u001b[38;5;241m.\u001b[39mrec(\u001b[38;5;28mint\u001b[39m(duration \u001b[38;5;241m*\u001b[39m samplerate), samplerate\u001b[38;5;241m=\u001b[39msamplerate, channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint16\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43msd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m audio_data\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sounddevice.py:398\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(ignore_errors)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for `play()`/`rec()`/`playrec()` to be finished.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \n\u001b[1;32m    384\u001b[0m \u001b[38;5;124;03mPlayback/recording can be stopped with a `KeyboardInterrupt`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    395\u001b[0m \n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _last_callback:\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_last_callback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sounddevice.py:2645\u001b[0m, in \u001b[0;36m_CallbackContext.wait\u001b[0;34m(self, ignore_errors)\u001b[0m\n\u001b[1;32m   2639\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for finished_callback.\u001b[39;00m\n\u001b[1;32m   2640\u001b[0m \n\u001b[1;32m   2641\u001b[0m \u001b[38;5;124;03mCan be interrupted with a KeyboardInterrupt.\u001b[39;00m\n\u001b[1;32m   2642\u001b[0m \n\u001b[1;32m   2643\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2644\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2645\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2646\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2647\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mclose(ignore_errors)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    653\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 355\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def run_conversation():\n",
    "    order_history=[]\n",
    "    while True:\n",
    "        print(\"Say something...\")\n",
    "        audio_data = record_audio(duration=5)\n",
    "        save_audio(audio_data)\n",
    "        \n",
    "        transcription = transcribe_audio('audio.wav')\n",
    "        print(f\"Transcription: {transcription}\")\n",
    "\n",
    "        # Process user query, for example, ordering logic (pseudo-code)\n",
    "        if transcription.lower() == \"çıkış\":\n",
    "            if order_history:\n",
    "                print(\"Siparişleriniz:\", order_history)\n",
    "                confirmation = input(\"Onaylıyor musunuz? (Evet/Hayır): \")\n",
    "                if confirmation.lower() == \"evet\":\n",
    "                    with open(\"siparisler.txt\", \"w\") as f:\n",
    "                        for item in order_history:\n",
    "                            f.write(f\"{item['sip_name']} x {item['sip_count']}\\n\")\n",
    "                    print(\"Siparişleriniz kaydedildi.\")\n",
    "                else:\n",
    "                    print(\"Siparişleriniz iptal edildi.\")\n",
    "            break\n",
    "\n",
    "        #corrected_query = correct_spelling_with_gpt(transcription)  # Assume function for spelling correction\n",
    "        #print(f\"Düzeltilmiş Soru: {corrected_query}\")\n",
    "        \n",
    "        rag_output = rag_chain.invoke({\"query\": transcription})  # Assume RAG model processing\n",
    "        print(f\"RAG Yanıtı: {rag_output['result']}\")\n",
    "\n",
    "\n",
    "\n",
    "        quest=query_analyzer.invoke({\"query\": transcription})\n",
    "\n",
    "\n",
    "    # check_sip_in_menu fonksiyonunu çalıştırıyoruz\n",
    "        sip_check_result = check_sip_in_menu(quest, data)\n",
    "\n",
    "        # Siparişi hafızada tutuyoruz, eğer ürün menüde varsa\n",
    "        for result in sip_check_result:\n",
    "            if result.get(\"exists_in_menu\", True):\n",
    "                order_history.append(result)\n",
    "\n",
    "        # Kullanıcıya yanıt veriyoruz\n",
    "        \n",
    "        print(\"Sipariş Durumu:\", sip_check_result)\n",
    "\n",
    "\n",
    "        # Respond with text-to-speech\n",
    "        text_to_speech(rag_output['result'])\n",
    "\n",
    "# Start the conversation\n",
    "run_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a894463a-7414-46b0-aff2-88ad8a5aa678",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('audio.wav', 'rb') as f:\n",
    "    audio_data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "92966640-16a2-4152-a978-f28d9988a91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c5021985-f453-471f-96f0-8156f6db8d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/04/nhwvkmt13753zn37rgwn35zr0000gn/T/tmpl0jm7hhp.wav':\n",
      "  Duration: 00:00:05.00, bitrate: 256 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, 1 channels, s16, 256 kb/s\n",
      "   4.91 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "# Load the audio file\n",
    "audio = AudioSegment.from_wav(\"audio.wav\")\n",
    "\n",
    "# Play the audio\n",
    "play(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade89f1c-c878-41c5-aa16-18a1412e3dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571011dc-1f40-4138-8953-b231f1876b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73484935-d3d1-4a6c-8ff9-559cd5b6e686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c180447-8ac9-4b7d-b43c-f995dedaefd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai-whisper gtts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e2a429-8c0e-4a24-ad7a-f4ef167cddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!#pip install sounddevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e38ab185-551c-4761-a8b8-af58dbe3130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "import os\n",
    "\n",
    "def text_to_speech(text, filename=\"output.mp3\"):\n",
    "    tts = gTTS(text, lang='tr')\n",
    "    tts.save(filename)\n",
    "    os.system(f\"afplay {filename}\")  # macOS için afplay komutu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801b7be1-7a32-463a-a8ea-ede2b2380a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade certifi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7085a470-4fca-4111-afc2-7226035de286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f19526-311e-4dae-88ae-f58467a763db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_conversation():\n",
    "    order_history = []\n",
    "\n",
    "    while True:\n",
    "        # Sesli giriş alıyoruz\n",
    "        audio_file = record_audio()\n",
    "        query = transcribe_audio(audio_file)\n",
    "        print(f\"Algılanan Soru: {query}\")\n",
    "\n",
    "        # 'exit' komutu ile çıkış\n",
    "        if query.lower() == \"exit\":\n",
    "            if order_history:\n",
    "                print(\"Siparişleriniz:\", order_history)\n",
    "                confirmation = input(\"Onaylıyor musunuz? (Evet/Hayır): \")\n",
    "                if confirmation.lower() == \"evet\":\n",
    "                    with open(\"siparisler.txt\", \"w\") as f:\n",
    "                        for item in order_history:\n",
    "                            f.write(f\"{item['sip_name']} x {item['sip_count']}\\n\")\n",
    "                    print(\"Siparişleriniz kaydedildi.\")\n",
    "                else:\n",
    "                    print(\"Siparişleriniz iptal edildi.\")\n",
    "            break\n",
    "\n",
    "        corrected_query = correct_spelling_with_gpt(query)\n",
    "        print(f\"Düzeltilmiş Soru: {corrected_query}\")\n",
    "\n",
    "        # RAG zincirinden yanıt alıyoruz\n",
    "        rag_output = rag_chain.invoke({\"query\": corrected_query})\n",
    "        response_text = rag_output[\"result\"]\n",
    "        print(\"RAG Yanıtı:\", response_text)\n",
    "\n",
    "        quest = query_analyzer.invoke({\"query\": corrected_query})\n",
    "\n",
    "        # check_sip_in_menu fonksiyonunu çalıştırıyoruz\n",
    "        sip_check_result = check_sip_in_menu(quest, data)\n",
    "\n",
    "        # Siparişi hafızada tutuyoruz\n",
    "        for result in sip_check_result:\n",
    "            if result.get(\"exists_in_menu\", False):\n",
    "                order_history.append(result)\n",
    "\n",
    "        # Yanıtı sesli olarak veriyoruz\n",
    "        text_to_speech(response_text)\n",
    "        print(\"Sipariş Durumu:\", sip_check_result)\n",
    "\n",
    "# Konuşma başlatma\n",
    "run_conversation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80f9e87-c832-4065-a5b0-5b523782623c",
   "metadata": {},
   "source": [
    "# text correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "34f623a8-aa07-4f98-939c-ef72a0463ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.18.0.post0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: nltk>=3.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk>=3.8->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk>=3.8->textblob) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk>=3.8->textblob) (4.66.5)\n",
      "Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.3/626.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: textblob\n",
      "Successfully installed textblob-0.18.0.post0\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "95bd4c0e-461f-43f0-acc1-f5d75f386097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 hamburgaer istiyorum anna 1 kolya\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def correct_spelling(text: str) -> str:\n",
    "    blob = TextBlob(text)\n",
    "    return str(blob.correct())\n",
    "\n",
    "# Kullanım\n",
    "user_input = \"2 hamburgaer istiyorum yanina 1 kola\"\n",
    "corrected_input = correct_spelling(user_input)\n",
    "print(corrected_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2986c0b2-921e-4263-a87a-3e02ed302102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting zemberek-python\n",
      "  Downloading zemberek_python-0.2.3-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting antlr4-python3-runtime==4.8 (from zemberek-python)\n",
      "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.19.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from zemberek-python) (1.26.4)\n",
      "Downloading zemberek_python-0.2.3-py3-none-any.whl (95.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.1/95.1 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141213 sha256=0f89d17fbf02a05e2c67c9972d84ac28f917db9c67328ca81cd99a37b15f8c03\n",
      "  Stored in directory: /Users/gayecetindere/Library/Caches/pip/wheels/3e/92/b7/08c6a108fc5bf6370a7540d11bbe9befc99b7e045ac7558d49\n",
      "Successfully built antlr4-python3-runtime\n",
      "Installing collected packages: antlr4-python3-runtime, zemberek-python\n",
      "Successfully installed antlr4-python3-runtime-4.8 zemberek-python-0.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install zemberek-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0f212afc-b289-440c-a0ba-d246a8110d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-03 08:10:33,699 - zemberek.morphology.turkish_morphology - INFO\n",
      "Msg: TurkishMorphology instance initialized in 3.0910708904266357\n",
      "\n",
      "2 hamburgaer istiyorum yanina 1 kola\n"
     ]
    }
   ],
   "source": [
    "from zemberek import TurkishMorphology, TurkishSpellChecker\n",
    "\n",
    "# Türkçe morfolojik analiz için gerekli yapıyı oluşturuyoruz\n",
    "morphology = TurkishMorphology.create_with_defaults()\n",
    "\n",
    "# SpellChecker'ı doğru başlatıyoruz\n",
    "spell_checker = TurkishSpellChecker(morphology)\n",
    "\n",
    "# Yazım düzeltme fonksiyonu\n",
    "def correct_spelling(text: str) -> str:\n",
    "    # Zemberek'teki yazım hatalarını düzeltme işlemi\n",
    "    corrections = spell_checker.suggest_for_word(text)\n",
    "    if corrections:\n",
    "        # İlk öneriyi alıyoruz (en doğru öneri)\n",
    "        return corrections[0].word\n",
    "    return text  # Eğer düzeltme yapılmazsa orijinal metni döndürüyoruz\n",
    "\n",
    "# Kullanım örneği\n",
    "user_input = \"2 hamburgaer istiyorum yanina 1 kola\"\n",
    "corrected_input = correct_spelling(user_input)\n",
    "print(corrected_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "67ade18d-a025-4b59-b50b-51885209fb12",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AIMessage' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Kullanıcıdan gelen yazılı metin\u001b[39;00m\n\u001b[1;32m     14\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2 hamburgaer istiyorum yanina 1 kola ayrica bide izgara tavuk istiyeourm \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 15\u001b[0m corrected_input \u001b[38;5;241m=\u001b[39m \u001b[43mcorrect_spelling_with_gpt\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDüzeltilmiş Metin:\u001b[39m\u001b[38;5;124m\"\u001b[39m, corrected_input)\n",
      "Cell \u001b[0;32mIn[41], line 10\u001b[0m, in \u001b[0;36mcorrect_spelling_with_gpt\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      8\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYazım hatalarını düzelt: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m response \u001b[38;5;241m=\u001b[39m llm(prompt)  \u001b[38;5;66;03m# Model cevabını alıyoruz\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m corrected_text \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m()  \u001b[38;5;66;03m# Yanıtı al ve strip uygula\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m corrected_text\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pydantic/main.py:856\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AIMessage' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "# LLM modelini yükleyin (OpenAI GPT-3 örneği)\n",
    "\n",
    "\n",
    "# Yazım düzeltme prompt'u\n",
    "def correct_spelling_with_gpt(text: str) -> str:\n",
    "    prompt = f\"Yazım hatalarını düzelt: '{text}'\"\n",
    "    response = llm(prompt)  # Model cevabını alıyoruz\n",
    "    corrected_text = response.strip()  # Yanıtı al ve strip uygula\n",
    "    return corrected_text\n",
    "\n",
    "# Kullanıcıdan gelen yazılı metin\n",
    "user_input = \"2 hamburgaer istiyorum yanina 1 kola ayrica bide izgara tavuk istiyeourm \"\n",
    "corrected_input = correct_spelling_with_gpt(user_input)\n",
    "\n",
    "print(\"Düzeltilmiş Metin:\", corrected_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94856f79-e8fd-4b23-8afb-838d9c09bd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/04/nhwvkmt13753zn37rgwn35zr0000gn/T/ipykernel_40192/3168142991.py:4: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI()\n",
      "/var/folders/04/nhwvkmt13753zn37rgwn35zr0000gn/T/ipykernel_40192/3168142991.py:9: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = llm(prompt)  # Model cevabını alıyoruz\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Kullanıcıdan gelen yazılı metin\u001b[39;00m\n\u001b[1;32m     14\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2 hamburgaer istiyorum yanina 1 kola ayrica bide izgara tavuk istiyeourm \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 15\u001b[0m corrected_input \u001b[38;5;241m=\u001b[39m \u001b[43mcorrect_spelling_with_gpt\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDüzeltilmiş Metin:\u001b[39m\u001b[38;5;124m\"\u001b[39m, corrected_input)\n",
      "Cell \u001b[0;32mIn[42], line 10\u001b[0m, in \u001b[0;36mcorrect_spelling_with_gpt\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      8\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYazım hatalarını düzelt: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m response \u001b[38;5;241m=\u001b[39m llm(prompt)  \u001b[38;5;66;03m# Model cevabını alıyoruz\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m corrected_text \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()  \u001b[38;5;66;03m# Yanıtın metin kısmını al ve strip uygula\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m corrected_text\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "# LLM modelini yükleyin (OpenAI GPT-3 örneği)\n",
    "llm = OpenAI()\n",
    "\n",
    "# Yazım düzeltme prompt'u\n",
    "def correct_spelling_with_gpt(text: str) -> str:\n",
    "    prompt = f\"Yazım hatalarını düzelt: '{text}'\"\n",
    "    response = llm(prompt)  # Model cevabını alıyoruz\n",
    "    corrected_text = response['text'].strip()  # Yanıtın metin kısmını al ve strip uygula\n",
    "    return corrected_text\n",
    "\n",
    "# Kullanıcıdan gelen yazılı metin\n",
    "user_input = \"2 hamburgaer istiyorum yanina 1 kola ayrica bide izgara tavuk istiyeourm \"\n",
    "corrected_input = correct_spelling_with_gpt(user_input)\n",
    "\n",
    "print(\"Düzeltilmiş Metin:\", corrected_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c8ffae08-e062-4b04-9f27-48cd49afd1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"2 hamburger istiyorum, yanına 1 kola ve ayrıca bir de ızgara tavuk istiyorum.\"\n",
      "Düzeltilmiş Metin: \"2 hamburger istiyorum, yanına 1 kola ve ayrıca bir de ızgara tavuk istiyorum.\"\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m corrected_input \u001b[38;5;241m=\u001b[39m correct_spelling_with_gpt(user_input)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDüzeltilmiş Metin:\u001b[39m\u001b[38;5;124m\"\u001b[39m, corrected_input)\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresponse\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "# LLM modelini yükleyin (OpenAI GPT-3 örneği)\n",
    "llm = OpenAI()\n",
    "\n",
    "# Yazım düzeltme prompt'u\n",
    "def correct_spelling_with_gpt(text: str) -> str:\n",
    "    prompt = f\"Yazım hatalarını düzelt: '{text}'\"\n",
    "    response = llm(prompt)  # Model cevabını alıyoruz\n",
    "    \n",
    "    # Eğer response bir liste veya nesne ise, metni çıkar\n",
    "    corrected_text = response[0].text.strip() if isinstance(response, list) else response.strip()\n",
    "    \n",
    "    \n",
    "    return corrected_text\n",
    "\n",
    "# Kullanıcıdan gelen yazılı metin\n",
    "user_input = \"2 hamburgaer istiyorum yanina 1 kola ayrica bide izgara tavuk istiyeourm \"\n",
    "corrected_input = correct_spelling_with_gpt(user_input)\n",
    "\n",
    "print(\"Düzeltilmiş Metin:\", corrected_input)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "567d79b4-f361-4b1c-bdd2-9f965ca2c84c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresponse\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c43373-85bb-4011-963d-e2cb7dbff84e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
